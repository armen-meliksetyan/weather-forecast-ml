{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>temperature_2m (°C)</th>\n",
       "      <th>precipitation (mm)</th>\n",
       "      <th>rain (mm)</th>\n",
       "      <th>cloudcover (%)</th>\n",
       "      <th>cloudcover_low (%)</th>\n",
       "      <th>cloudcover_mid (%)</th>\n",
       "      <th>cloudcover_high (%)</th>\n",
       "      <th>windspeed_10m (km/h)</th>\n",
       "      <th>winddirection_10m (°)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>7.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>296.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-01 01:00:00</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>9.8</td>\n",
       "      <td>287.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-01 02:00:00</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>285.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-01 03:00:00</td>\n",
       "      <td>6.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>9.2</td>\n",
       "      <td>281.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-01 04:00:00</td>\n",
       "      <td>6.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>9.1</td>\n",
       "      <td>279.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 time  temperature_2m (°C)  precipitation (mm)  rain (mm)  \\\n",
       "0 2016-01-01 00:00:00                  7.6                 0.0        0.0   \n",
       "1 2016-01-01 01:00:00                  7.5                 0.0        0.0   \n",
       "2 2016-01-01 02:00:00                  7.1                 0.0        0.0   \n",
       "3 2016-01-01 03:00:00                  6.6                 0.0        0.0   \n",
       "4 2016-01-01 04:00:00                  6.3                 0.0        0.0   \n",
       "\n",
       "   cloudcover (%)  cloudcover_low (%)  cloudcover_mid (%)  \\\n",
       "0            69.0                53.0                 0.0   \n",
       "1            20.0                 4.0                 0.0   \n",
       "2            32.0                 3.0                 0.0   \n",
       "3            35.0                 5.0                 0.0   \n",
       "4            34.0                 4.0                 0.0   \n",
       "\n",
       "   cloudcover_high (%)  windspeed_10m (km/h)  winddirection_10m (°)  \n",
       "0                 72.0                  10.0                  296.0  \n",
       "1                 56.0                   9.8                  287.0  \n",
       "2                 99.0                   9.7                  285.0  \n",
       "3                100.0                   9.2                  281.0  \n",
       "4                100.0                   9.1                  279.0  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "data = pd.read_csv('../data/NYC_Weather_2016_2022.csv')\n",
    "\n",
    "data['time'] = pd.to_datetime(data['time'])\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data['day'] = data['time'].dt.day\n",
    "data['year'] = data['time'].dt.year\n",
    "# data['day_of_year'] = data['time'].dt.dayofyear  # 1-365\n",
    "\n",
    "data['hour_sin'] = np.sin(2 * np.pi * data['time'].dt.hour / 24)\n",
    "data['hour_cos'] = np.cos(2 * np.pi * data['time'].dt.hour / 24)\n",
    "data['month_sin'] = np.sin(2 * np.pi * (data['time'].dt.month - 1) / 12)\n",
    "data['month_cos'] = np.cos(2 * np.pi * (data['time'].dt.month - 1) / 12)\n",
    "\n",
    "# Create lagged features for temperature\n",
    "LAGS_NUM = 24\n",
    "for i in range(1, LAGS_NUM + 1):\n",
    "    data[f'temp_lag_{i}'] = data['temperature_2m (°C)'].shift(i)\n",
    "\n",
    "data['target'] = data['temperature_2m (°C)'].shift(-1)\n",
    "\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>temperature_2m (°C)</th>\n",
       "      <th>precipitation (mm)</th>\n",
       "      <th>rain (mm)</th>\n",
       "      <th>cloudcover (%)</th>\n",
       "      <th>cloudcover_low (%)</th>\n",
       "      <th>cloudcover_mid (%)</th>\n",
       "      <th>cloudcover_high (%)</th>\n",
       "      <th>windspeed_10m (km/h)</th>\n",
       "      <th>winddirection_10m (°)</th>\n",
       "      <th>...</th>\n",
       "      <th>temp_lag_16</th>\n",
       "      <th>temp_lag_17</th>\n",
       "      <th>temp_lag_18</th>\n",
       "      <th>temp_lag_19</th>\n",
       "      <th>temp_lag_20</th>\n",
       "      <th>temp_lag_21</th>\n",
       "      <th>temp_lag_22</th>\n",
       "      <th>temp_lag_23</th>\n",
       "      <th>temp_lag_24</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2016-01-02 00:00:00</td>\n",
       "      <td>3.6</td>\n",
       "      <td>-0.246422</td>\n",
       "      <td>-0.234733</td>\n",
       "      <td>-0.847534</td>\n",
       "      <td>-0.661924</td>\n",
       "      <td>-0.274548</td>\n",
       "      <td>-0.946749</td>\n",
       "      <td>0.709761</td>\n",
       "      <td>0.654930</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.759576</td>\n",
       "      <td>-0.749379</td>\n",
       "      <td>-0.739179</td>\n",
       "      <td>-0.728976</td>\n",
       "      <td>-0.708579</td>\n",
       "      <td>-0.677982</td>\n",
       "      <td>-0.626990</td>\n",
       "      <td>-0.586199</td>\n",
       "      <td>-0.575998</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2016-01-02 01:00:00</td>\n",
       "      <td>3.1</td>\n",
       "      <td>-0.246422</td>\n",
       "      <td>-0.234733</td>\n",
       "      <td>-1.187218</td>\n",
       "      <td>-0.688829</td>\n",
       "      <td>-0.817338</td>\n",
       "      <td>-0.946749</td>\n",
       "      <td>0.778698</td>\n",
       "      <td>0.695034</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.759576</td>\n",
       "      <td>-0.759576</td>\n",
       "      <td>-0.749376</td>\n",
       "      <td>-0.739173</td>\n",
       "      <td>-0.728972</td>\n",
       "      <td>-0.708572</td>\n",
       "      <td>-0.677973</td>\n",
       "      <td>-0.626985</td>\n",
       "      <td>-0.586194</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2016-01-02 02:00:00</td>\n",
       "      <td>2.9</td>\n",
       "      <td>-0.246422</td>\n",
       "      <td>-0.234733</td>\n",
       "      <td>-1.187218</td>\n",
       "      <td>-0.688829</td>\n",
       "      <td>-0.817338</td>\n",
       "      <td>-0.946749</td>\n",
       "      <td>0.640824</td>\n",
       "      <td>0.654930</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.871739</td>\n",
       "      <td>-0.759576</td>\n",
       "      <td>-0.759572</td>\n",
       "      <td>-0.749370</td>\n",
       "      <td>-0.739169</td>\n",
       "      <td>-0.728965</td>\n",
       "      <td>-0.708562</td>\n",
       "      <td>-0.677967</td>\n",
       "      <td>-0.626979</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2016-01-02 03:00:00</td>\n",
       "      <td>2.3</td>\n",
       "      <td>-0.246422</td>\n",
       "      <td>-0.234733</td>\n",
       "      <td>-1.187218</td>\n",
       "      <td>-0.688829</td>\n",
       "      <td>-0.817338</td>\n",
       "      <td>-0.946749</td>\n",
       "      <td>0.709761</td>\n",
       "      <td>0.634878</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.871739</td>\n",
       "      <td>-0.871739</td>\n",
       "      <td>-0.759572</td>\n",
       "      <td>-0.759566</td>\n",
       "      <td>-0.749365</td>\n",
       "      <td>-0.739161</td>\n",
       "      <td>-0.728955</td>\n",
       "      <td>-0.708556</td>\n",
       "      <td>-0.677961</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2016-01-02 04:00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.246422</td>\n",
       "      <td>-0.234733</td>\n",
       "      <td>-1.187218</td>\n",
       "      <td>-0.688829</td>\n",
       "      <td>-0.817338</td>\n",
       "      <td>-0.946749</td>\n",
       "      <td>0.709761</td>\n",
       "      <td>0.654930</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.861543</td>\n",
       "      <td>-0.871739</td>\n",
       "      <td>-0.871736</td>\n",
       "      <td>-0.759566</td>\n",
       "      <td>-0.759562</td>\n",
       "      <td>-0.749358</td>\n",
       "      <td>-0.739151</td>\n",
       "      <td>-0.728949</td>\n",
       "      <td>-0.708550</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  time  temperature_2m (°C)  precipitation (mm)  rain (mm)  \\\n",
       "24 2016-01-02 00:00:00                  3.6           -0.246422  -0.234733   \n",
       "25 2016-01-02 01:00:00                  3.1           -0.246422  -0.234733   \n",
       "26 2016-01-02 02:00:00                  2.9           -0.246422  -0.234733   \n",
       "27 2016-01-02 03:00:00                  2.3           -0.246422  -0.234733   \n",
       "28 2016-01-02 04:00:00                  2.0           -0.246422  -0.234733   \n",
       "\n",
       "    cloudcover (%)  cloudcover_low (%)  cloudcover_mid (%)  \\\n",
       "24       -0.847534           -0.661924           -0.274548   \n",
       "25       -1.187218           -0.688829           -0.817338   \n",
       "26       -1.187218           -0.688829           -0.817338   \n",
       "27       -1.187218           -0.688829           -0.817338   \n",
       "28       -1.187218           -0.688829           -0.817338   \n",
       "\n",
       "    cloudcover_high (%)  windspeed_10m (km/h)  winddirection_10m (°)  ...  \\\n",
       "24            -0.946749              0.709761               0.654930  ...   \n",
       "25            -0.946749              0.778698               0.695034  ...   \n",
       "26            -0.946749              0.640824               0.654930  ...   \n",
       "27            -0.946749              0.709761               0.634878  ...   \n",
       "28            -0.946749              0.709761               0.654930  ...   \n",
       "\n",
       "    temp_lag_16  temp_lag_17  temp_lag_18  temp_lag_19  temp_lag_20  \\\n",
       "24    -0.759576    -0.749379    -0.739179    -0.728976    -0.708579   \n",
       "25    -0.759576    -0.759576    -0.749376    -0.739173    -0.728972   \n",
       "26    -0.871739    -0.759576    -0.759572    -0.749370    -0.739169   \n",
       "27    -0.871739    -0.871739    -0.759572    -0.759566    -0.749365   \n",
       "28    -0.861543    -0.871739    -0.871736    -0.759566    -0.759562   \n",
       "\n",
       "    temp_lag_21  temp_lag_22  temp_lag_23  temp_lag_24  target  \n",
       "24    -0.677982    -0.626990    -0.586199    -0.575998     3.1  \n",
       "25    -0.708572    -0.677973    -0.626985    -0.586194     2.9  \n",
       "26    -0.728965    -0.708562    -0.677967    -0.626979     2.3  \n",
       "27    -0.739161    -0.728955    -0.708556    -0.677961     2.0  \n",
       "28    -0.749358    -0.739151    -0.728949    -0.708550     1.9  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "numerical_features = ['precipitation (mm)', 'rain (mm)', 'cloudcover (%)', \n",
    "                      'cloudcover_low (%)', 'cloudcover_mid (%)', 'cloudcover_high (%)', \n",
    "                      'windspeed_10m (km/h)', 'winddirection_10m (°)'] + [f'temp_lag_{i}' for i in range(1, LAGS_NUM + 1)]\n",
    "\n",
    "data[numerical_features] = scaler.fit_transform(data[numerical_features])\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = numerical_features + ['temperature_2m (°C)', 'day', 'year', 'hour_sin', 'hour_cos', 'month_sin', 'month_cos']\n",
    "\n",
    "train_data = data[(data['year'] >= 2016) & (data['year'] <= 2020)]\n",
    "val_data = data[data['year'] == 2021]\n",
    "test_data = data[data['year'] == 2022]\n",
    "\n",
    "def df_to_tensor(df, feature_cols, target_col):\n",
    "    X = torch.tensor(df[feature_cols].values, dtype=torch.float32)\n",
    "    y = torch.tensor(df[target_col].values, dtype=torch.float32).unsqueeze(1)\n",
    "    return X, y\n",
    "\n",
    "X_train, y_train = df_to_tensor(train_data, features, 'target')\n",
    "X_val, y_val = df_to_tensor(val_data, features, 'target')\n",
    "X_test, y_test = df_to_tensor(test_data, features, 'target')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single-Layer Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Train Loss = 13523.5791, Val Loss = 9260.5928\n",
      "Epoch 10: Train Loss = 1694.2975, Val Loss = 1969.8350\n",
      "Epoch 20: Train Loss = 14.1291, Val Loss = 47.9071\n",
      "Epoch 30: Train Loss = 206.9712, Val Loss = 118.9634\n",
      "Epoch 40: Train Loss = 127.8408, Val Loss = 113.0841\n",
      "Epoch 50: Train Loss = 32.6555, Val Loss = 39.0648\n",
      "Epoch 60: Train Loss = 7.7501, Val Loss = 10.6714\n",
      "Epoch 70: Train Loss = 4.9746, Val Loss = 5.1119\n",
      "Epoch 80: Train Loss = 4.8677, Val Loss = 4.4105\n",
      "Epoch 90: Train Loss = 4.6765, Val Loss = 4.2267\n",
      "Epoch 100: Train Loss = 4.4305, Val Loss = 4.0463\n",
      "Epoch 110: Train Loss = 4.2203, Val Loss = 3.8685\n",
      "Epoch 120: Train Loss = 4.0484, Val Loss = 3.7115\n",
      "Epoch 130: Train Loss = 3.8989, Val Loss = 3.5677\n",
      "Epoch 140: Train Loss = 3.7627, Val Loss = 3.4347\n",
      "Epoch 150: Train Loss = 3.6360, Val Loss = 3.3113\n",
      "Epoch 160: Train Loss = 3.5171, Val Loss = 3.1956\n",
      "Epoch 170: Train Loss = 3.4050, Val Loss = 3.0880\n",
      "Epoch 180: Train Loss = 3.2993, Val Loss = 2.9873\n",
      "Epoch 190: Train Loss = 3.1995, Val Loss = 2.8934\n",
      "Epoch 200: Train Loss = 3.1052, Val Loss = 2.8053\n",
      "Epoch 210: Train Loss = 3.0157, Val Loss = 2.7227\n",
      "Epoch 220: Train Loss = 2.9308, Val Loss = 2.6449\n",
      "Epoch 230: Train Loss = 2.8500, Val Loss = 2.5717\n",
      "Epoch 240: Train Loss = 2.7731, Val Loss = 2.5025\n",
      "Epoch 250: Train Loss = 2.6997, Val Loss = 2.4371\n",
      "Epoch 260: Train Loss = 2.6296, Val Loss = 2.3751\n",
      "Epoch 270: Train Loss = 2.5626, Val Loss = 2.3164\n",
      "Epoch 280: Train Loss = 2.4986, Val Loss = 2.2606\n",
      "Epoch 290: Train Loss = 2.4373, Val Loss = 2.2077\n",
      "Epoch 300: Train Loss = 2.3787, Val Loss = 2.1573\n",
      "Epoch 310: Train Loss = 2.3226, Val Loss = 2.1094\n",
      "Epoch 320: Train Loss = 2.2689, Val Loss = 2.0639\n",
      "Epoch 330: Train Loss = 2.2175, Val Loss = 2.0205\n",
      "Epoch 340: Train Loss = 2.1683, Val Loss = 1.9792\n",
      "Epoch 350: Train Loss = 2.1213, Val Loss = 1.9399\n",
      "Epoch 360: Train Loss = 2.0763, Val Loss = 1.9026\n",
      "Epoch 370: Train Loss = 2.0333, Val Loss = 1.8670\n",
      "Epoch 380: Train Loss = 1.9922, Val Loss = 1.8331\n",
      "Epoch 390: Train Loss = 1.9530, Val Loss = 1.8008\n",
      "Epoch 400: Train Loss = 1.9155, Val Loss = 1.7702\n",
      "Epoch 410: Train Loss = 1.8798, Val Loss = 1.7410\n",
      "Epoch 420: Train Loss = 1.8456, Val Loss = 1.7132\n",
      "Epoch 430: Train Loss = 1.8130, Val Loss = 1.6867\n",
      "Epoch 440: Train Loss = 1.7820, Val Loss = 1.6615\n",
      "Epoch 450: Train Loss = 1.7523, Val Loss = 1.6376\n",
      "Epoch 460: Train Loss = 1.7240, Val Loss = 1.6147\n",
      "Epoch 470: Train Loss = 1.6970, Val Loss = 1.5930\n",
      "Epoch 480: Train Loss = 1.6713, Val Loss = 1.5723\n",
      "Epoch 490: Train Loss = 1.6467, Val Loss = 1.5525\n",
      "Epoch 500: Train Loss = 1.6233, Val Loss = 1.5337\n",
      "Epoch 510: Train Loss = 1.6009, Val Loss = 1.5157\n",
      "Epoch 520: Train Loss = 1.5794, Val Loss = 1.4985\n",
      "Epoch 530: Train Loss = 1.5590, Val Loss = 1.4821\n",
      "Epoch 540: Train Loss = 1.5394, Val Loss = 1.4664\n",
      "Epoch 550: Train Loss = 1.5207, Val Loss = 1.4513\n",
      "Epoch 560: Train Loss = 1.5027, Val Loss = 1.4369\n",
      "Epoch 570: Train Loss = 1.4855, Val Loss = 1.4231\n",
      "Epoch 580: Train Loss = 1.4690, Val Loss = 1.4097\n",
      "Epoch 590: Train Loss = 1.4532, Val Loss = 1.3969\n",
      "Epoch 600: Train Loss = 1.4379, Val Loss = 1.3846\n",
      "Epoch 610: Train Loss = 1.4233, Val Loss = 1.3727\n",
      "Epoch 620: Train Loss = 1.4092, Val Loss = 1.3613\n",
      "Epoch 630: Train Loss = 1.3956, Val Loss = 1.3502\n",
      "Epoch 640: Train Loss = 1.3824, Val Loss = 1.3394\n",
      "Epoch 650: Train Loss = 1.3697, Val Loss = 1.3290\n",
      "Epoch 660: Train Loss = 1.3574, Val Loss = 1.3189\n",
      "Epoch 670: Train Loss = 1.3455, Val Loss = 1.3090\n",
      "Epoch 680: Train Loss = 1.3340, Val Loss = 1.2995\n",
      "Epoch 690: Train Loss = 1.3228, Val Loss = 1.2901\n",
      "Epoch 700: Train Loss = 1.3119, Val Loss = 1.2810\n",
      "Epoch 710: Train Loss = 1.3013, Val Loss = 1.2722\n",
      "Epoch 720: Train Loss = 1.2910, Val Loss = 1.2635\n",
      "Epoch 730: Train Loss = 1.2809, Val Loss = 1.2549\n",
      "Epoch 740: Train Loss = 1.2711, Val Loss = 1.2466\n",
      "Epoch 750: Train Loss = 1.2615, Val Loss = 1.2384\n",
      "Epoch 760: Train Loss = 1.2521, Val Loss = 1.2303\n",
      "Epoch 770: Train Loss = 1.2429, Val Loss = 1.2224\n",
      "Epoch 780: Train Loss = 1.2339, Val Loss = 1.2146\n",
      "Epoch 790: Train Loss = 1.2251, Val Loss = 1.2070\n",
      "Epoch 800: Train Loss = 1.2164, Val Loss = 1.1994\n",
      "Epoch 810: Train Loss = 1.2079, Val Loss = 1.1919\n",
      "Epoch 820: Train Loss = 1.1995, Val Loss = 1.1846\n",
      "Epoch 830: Train Loss = 1.1913, Val Loss = 1.1773\n",
      "Epoch 840: Train Loss = 1.1832, Val Loss = 1.1701\n",
      "Epoch 850: Train Loss = 1.1752, Val Loss = 1.1630\n",
      "Epoch 860: Train Loss = 1.1673, Val Loss = 1.1560\n",
      "Epoch 870: Train Loss = 1.1596, Val Loss = 1.1490\n",
      "Epoch 880: Train Loss = 1.1519, Val Loss = 1.1422\n",
      "Epoch 890: Train Loss = 1.1444, Val Loss = 1.1353\n",
      "Epoch 900: Train Loss = 1.1369, Val Loss = 1.1286\n",
      "Epoch 910: Train Loss = 1.1295, Val Loss = 1.1219\n",
      "Epoch 920: Train Loss = 1.1223, Val Loss = 1.1153\n",
      "Epoch 930: Train Loss = 1.1151, Val Loss = 1.1087\n",
      "Epoch 940: Train Loss = 1.1080, Val Loss = 1.1022\n",
      "Epoch 950: Train Loss = 1.1009, Val Loss = 1.0957\n",
      "Epoch 960: Train Loss = 1.0940, Val Loss = 1.0893\n",
      "Epoch 970: Train Loss = 1.0871, Val Loss = 1.0830\n",
      "Epoch 980: Train Loss = 1.0803, Val Loss = 1.0767\n",
      "Epoch 990: Train Loss = 1.0735, Val Loss = 1.0704\n",
      "Epoch 1000: Train Loss = 1.0669, Val Loss = 1.0642\n",
      "Epoch 1010: Train Loss = 1.0603, Val Loss = 1.0581\n",
      "Epoch 1020: Train Loss = 1.0537, Val Loss = 1.0520\n",
      "Epoch 1030: Train Loss = 1.0473, Val Loss = 1.0459\n",
      "Epoch 1040: Train Loss = 1.0408, Val Loss = 1.0399\n",
      "Epoch 1050: Train Loss = 1.0345, Val Loss = 1.0340\n",
      "Epoch 1060: Train Loss = 1.0282, Val Loss = 1.0280\n",
      "Epoch 1070: Train Loss = 1.0220, Val Loss = 1.0222\n",
      "Epoch 1080: Train Loss = 1.0158, Val Loss = 1.0163\n",
      "Epoch 1090: Train Loss = 1.0097, Val Loss = 1.0106\n",
      "Epoch 1100: Train Loss = 1.0036, Val Loss = 1.0048\n",
      "Epoch 1110: Train Loss = 0.9976, Val Loss = 0.9991\n",
      "Epoch 1120: Train Loss = 0.9916, Val Loss = 0.9935\n",
      "Epoch 1130: Train Loss = 0.9857, Val Loss = 0.9879\n",
      "Epoch 1140: Train Loss = 0.9799, Val Loss = 0.9823\n",
      "Epoch 1150: Train Loss = 0.9741, Val Loss = 0.9768\n",
      "Epoch 1160: Train Loss = 0.9683, Val Loss = 0.9714\n",
      "Epoch 1170: Train Loss = 0.9626, Val Loss = 0.9659\n",
      "Epoch 1180: Train Loss = 0.9570, Val Loss = 0.9605\n",
      "Epoch 1190: Train Loss = 0.9514, Val Loss = 0.9552\n",
      "Epoch 1200: Train Loss = 0.9459, Val Loss = 0.9499\n",
      "Epoch 1210: Train Loss = 0.9404, Val Loss = 0.9446\n",
      "Epoch 1220: Train Loss = 0.9349, Val Loss = 0.9394\n",
      "Epoch 1230: Train Loss = 0.9295, Val Loss = 0.9343\n",
      "Epoch 1240: Train Loss = 0.9242, Val Loss = 0.9291\n",
      "Epoch 1250: Train Loss = 0.9189, Val Loss = 0.9240\n",
      "Epoch 1260: Train Loss = 0.9136, Val Loss = 0.9190\n",
      "Epoch 1270: Train Loss = 0.9084, Val Loss = 0.9140\n",
      "Epoch 1280: Train Loss = 0.9032, Val Loss = 0.9090\n",
      "Epoch 1290: Train Loss = 0.8981, Val Loss = 0.9041\n",
      "Epoch 1300: Train Loss = 0.8930, Val Loss = 0.8992\n",
      "Epoch 1310: Train Loss = 0.8880, Val Loss = 0.8943\n",
      "Epoch 1320: Train Loss = 0.8830, Val Loss = 0.8895\n",
      "Epoch 1330: Train Loss = 0.8781, Val Loss = 0.8848\n",
      "Epoch 1340: Train Loss = 0.8732, Val Loss = 0.8800\n",
      "Epoch 1350: Train Loss = 0.8683, Val Loss = 0.8753\n",
      "Epoch 1360: Train Loss = 0.8635, Val Loss = 0.8707\n",
      "Epoch 1370: Train Loss = 0.8587, Val Loss = 0.8661\n",
      "Epoch 1380: Train Loss = 0.8540, Val Loss = 0.8615\n",
      "Epoch 1390: Train Loss = 0.8493, Val Loss = 0.8570\n",
      "Epoch 1400: Train Loss = 0.8447, Val Loss = 0.8525\n",
      "Epoch 1410: Train Loss = 0.8401, Val Loss = 0.8480\n",
      "Epoch 1420: Train Loss = 0.8355, Val Loss = 0.8436\n",
      "Epoch 1430: Train Loss = 0.8310, Val Loss = 0.8392\n",
      "Epoch 1440: Train Loss = 0.8265, Val Loss = 0.8348\n",
      "Epoch 1450: Train Loss = 0.8220, Val Loss = 0.8305\n",
      "Epoch 1460: Train Loss = 0.8176, Val Loss = 0.8263\n",
      "Epoch 1470: Train Loss = 0.8132, Val Loss = 0.8220\n",
      "Epoch 1480: Train Loss = 0.8089, Val Loss = 0.8178\n",
      "Epoch 1490: Train Loss = 0.8046, Val Loss = 0.8136\n",
      "Epoch 1500: Train Loss = 0.8004, Val Loss = 0.8095\n",
      "Epoch 1510: Train Loss = 0.7961, Val Loss = 0.8054\n",
      "Epoch 1520: Train Loss = 0.7919, Val Loss = 0.8013\n",
      "Epoch 1530: Train Loss = 0.7878, Val Loss = 0.7973\n",
      "Epoch 1540: Train Loss = 0.7837, Val Loss = 0.7933\n",
      "Epoch 1550: Train Loss = 0.7796, Val Loss = 0.7893\n",
      "Epoch 1560: Train Loss = 0.7756, Val Loss = 0.7854\n",
      "Epoch 1570: Train Loss = 0.7716, Val Loss = 0.7815\n",
      "Epoch 1580: Train Loss = 0.7676, Val Loss = 0.7776\n",
      "Epoch 1590: Train Loss = 0.7637, Val Loss = 0.7738\n",
      "Epoch 1600: Train Loss = 0.7598, Val Loss = 0.7700\n",
      "Epoch 1610: Train Loss = 0.7559, Val Loss = 0.7662\n",
      "Epoch 1620: Train Loss = 0.7521, Val Loss = 0.7625\n",
      "Epoch 1630: Train Loss = 0.7483, Val Loss = 0.7588\n",
      "Epoch 1640: Train Loss = 0.7445, Val Loss = 0.7551\n",
      "Epoch 1650: Train Loss = 0.7408, Val Loss = 0.7515\n",
      "Epoch 1660: Train Loss = 0.7371, Val Loss = 0.7479\n",
      "Epoch 1670: Train Loss = 0.7334, Val Loss = 0.7443\n",
      "Epoch 1680: Train Loss = 0.7298, Val Loss = 0.7407\n",
      "Epoch 1690: Train Loss = 0.7261, Val Loss = 0.7372\n",
      "Epoch 1700: Train Loss = 0.7226, Val Loss = 0.7337\n",
      "Epoch 1710: Train Loss = 0.7190, Val Loss = 0.7303\n",
      "Epoch 1720: Train Loss = 0.7155, Val Loss = 0.7268\n",
      "Epoch 1730: Train Loss = 0.7120, Val Loss = 0.7234\n",
      "Epoch 1740: Train Loss = 0.7086, Val Loss = 0.7200\n",
      "Epoch 1750: Train Loss = 0.7052, Val Loss = 0.7167\n",
      "Epoch 1760: Train Loss = 0.7018, Val Loss = 0.7134\n",
      "Epoch 1770: Train Loss = 0.6984, Val Loss = 0.7101\n",
      "Epoch 1780: Train Loss = 0.6951, Val Loss = 0.7068\n",
      "Epoch 1790: Train Loss = 0.6918, Val Loss = 0.7036\n",
      "Epoch 1800: Train Loss = 0.6885, Val Loss = 0.7004\n",
      "Epoch 1810: Train Loss = 0.6853, Val Loss = 0.6972\n",
      "Epoch 1820: Train Loss = 0.6821, Val Loss = 0.6941\n",
      "Epoch 1830: Train Loss = 0.6789, Val Loss = 0.6909\n",
      "Epoch 1840: Train Loss = 0.6757, Val Loss = 0.6878\n",
      "Epoch 1850: Train Loss = 0.6726, Val Loss = 0.6848\n",
      "Epoch 1860: Train Loss = 0.6695, Val Loss = 0.6817\n",
      "Epoch 1870: Train Loss = 0.6664, Val Loss = 0.6787\n",
      "Epoch 1880: Train Loss = 0.6634, Val Loss = 0.6757\n",
      "Epoch 1890: Train Loss = 0.6603, Val Loss = 0.6728\n",
      "Epoch 1900: Train Loss = 0.6573, Val Loss = 0.6698\n",
      "Epoch 1910: Train Loss = 0.6544, Val Loss = 0.6669\n",
      "Epoch 1920: Train Loss = 0.6514, Val Loss = 0.6640\n",
      "Epoch 1930: Train Loss = 0.6485, Val Loss = 0.6611\n",
      "Epoch 1940: Train Loss = 0.6456, Val Loss = 0.6583\n",
      "Epoch 1950: Train Loss = 0.6427, Val Loss = 0.6555\n",
      "Epoch 1960: Train Loss = 0.6399, Val Loss = 0.6527\n",
      "Epoch 1970: Train Loss = 0.6371, Val Loss = 0.6499\n",
      "Epoch 1980: Train Loss = 0.6343, Val Loss = 0.6472\n",
      "Epoch 1990: Train Loss = 0.6315, Val Loss = 0.6445\n",
      "Epoch 2000: Train Loss = 0.6288, Val Loss = 0.6418\n",
      "Epoch 2010: Train Loss = 0.6261, Val Loss = 0.6391\n",
      "Epoch 2020: Train Loss = 0.6234, Val Loss = 0.6364\n",
      "Epoch 2030: Train Loss = 0.6207, Val Loss = 0.6338\n",
      "Epoch 2040: Train Loss = 0.6181, Val Loss = 0.6312\n",
      "Epoch 2050: Train Loss = 0.6154, Val Loss = 0.6286\n",
      "Epoch 2060: Train Loss = 0.6128, Val Loss = 0.6260\n",
      "Epoch 2070: Train Loss = 0.6103, Val Loss = 0.6235\n",
      "Epoch 2080: Train Loss = 0.6077, Val Loss = 0.6210\n",
      "Epoch 2090: Train Loss = 0.6052, Val Loss = 0.6185\n",
      "Epoch 2100: Train Loss = 0.6027, Val Loss = 0.6160\n",
      "Epoch 2110: Train Loss = 0.6002, Val Loss = 0.6136\n",
      "Epoch 2120: Train Loss = 0.5977, Val Loss = 0.6111\n",
      "Epoch 2130: Train Loss = 0.5953, Val Loss = 0.6087\n",
      "Epoch 2140: Train Loss = 0.5928, Val Loss = 0.6063\n",
      "Epoch 2150: Train Loss = 0.5904, Val Loss = 0.6040\n",
      "Epoch 2160: Train Loss = 0.5881, Val Loss = 0.6016\n",
      "Epoch 2170: Train Loss = 0.5857, Val Loss = 0.5993\n",
      "Epoch 2180: Train Loss = 0.5834, Val Loss = 0.5970\n",
      "Epoch 2190: Train Loss = 0.5811, Val Loss = 0.5947\n",
      "Epoch 2200: Train Loss = 0.5788, Val Loss = 0.5924\n",
      "Epoch 2210: Train Loss = 0.5765, Val Loss = 0.5902\n",
      "Epoch 2220: Train Loss = 0.5742, Val Loss = 0.5879\n",
      "Epoch 2230: Train Loss = 0.5720, Val Loss = 0.5857\n",
      "Epoch 2240: Train Loss = 0.5698, Val Loss = 0.5835\n",
      "Epoch 2250: Train Loss = 0.5676, Val Loss = 0.5814\n",
      "Epoch 2260: Train Loss = 0.5654, Val Loss = 0.5792\n",
      "Epoch 2270: Train Loss = 0.5632, Val Loss = 0.5771\n",
      "Epoch 2280: Train Loss = 0.5611, Val Loss = 0.5750\n",
      "Epoch 2290: Train Loss = 0.5590, Val Loss = 0.5729\n",
      "Epoch 2300: Train Loss = 0.5569, Val Loss = 0.5708\n",
      "Epoch 2310: Train Loss = 0.5548, Val Loss = 0.5687\n",
      "Epoch 2320: Train Loss = 0.5527, Val Loss = 0.5667\n",
      "Epoch 2330: Train Loss = 0.5507, Val Loss = 0.5646\n",
      "Epoch 2340: Train Loss = 0.5487, Val Loss = 0.5626\n",
      "Epoch 2350: Train Loss = 0.5467, Val Loss = 0.5606\n",
      "Epoch 2360: Train Loss = 0.5447, Val Loss = 0.5587\n",
      "Epoch 2370: Train Loss = 0.5427, Val Loss = 0.5567\n",
      "Epoch 2380: Train Loss = 0.5407, Val Loss = 0.5548\n",
      "Epoch 2390: Train Loss = 0.5388, Val Loss = 0.5528\n",
      "Epoch 2400: Train Loss = 0.5369, Val Loss = 0.5509\n",
      "Epoch 2410: Train Loss = 0.5350, Val Loss = 0.5490\n",
      "Epoch 2420: Train Loss = 0.5331, Val Loss = 0.5472\n",
      "Epoch 2430: Train Loss = 0.5312, Val Loss = 0.5453\n",
      "Epoch 2440: Train Loss = 0.5294, Val Loss = 0.5435\n",
      "Epoch 2450: Train Loss = 0.5275, Val Loss = 0.5416\n",
      "Epoch 2460: Train Loss = 0.5257, Val Loss = 0.5398\n",
      "Epoch 2470: Train Loss = 0.5239, Val Loss = 0.5380\n",
      "Epoch 2480: Train Loss = 0.5221, Val Loss = 0.5363\n",
      "Epoch 2490: Train Loss = 0.5203, Val Loss = 0.5345\n",
      "Epoch 2500: Train Loss = 0.5186, Val Loss = 0.5327\n",
      "Epoch 2510: Train Loss = 0.5168, Val Loss = 0.5310\n",
      "Epoch 2520: Train Loss = 0.5151, Val Loss = 0.5293\n",
      "Epoch 2530: Train Loss = 0.5134, Val Loss = 0.5276\n",
      "Epoch 2540: Train Loss = 0.5117, Val Loss = 0.5259\n",
      "Epoch 2550: Train Loss = 0.5100, Val Loss = 0.5242\n",
      "Epoch 2560: Train Loss = 0.5084, Val Loss = 0.5226\n",
      "Epoch 2570: Train Loss = 0.5067, Val Loss = 0.5209\n",
      "Epoch 2580: Train Loss = 0.5051, Val Loss = 0.5193\n",
      "Epoch 2590: Train Loss = 0.5034, Val Loss = 0.5177\n",
      "Epoch 2600: Train Loss = 0.5018, Val Loss = 0.5161\n",
      "Epoch 2610: Train Loss = 0.5002, Val Loss = 0.5145\n",
      "Epoch 2620: Train Loss = 0.4987, Val Loss = 0.5129\n",
      "Epoch 2630: Train Loss = 0.4971, Val Loss = 0.5113\n",
      "Epoch 2640: Train Loss = 0.4955, Val Loss = 0.5098\n",
      "Epoch 2650: Train Loss = 0.4940, Val Loss = 0.5083\n",
      "Epoch 2660: Train Loss = 0.4925, Val Loss = 0.5067\n",
      "Epoch 2670: Train Loss = 0.4910, Val Loss = 0.5052\n",
      "Epoch 2680: Train Loss = 0.4895, Val Loss = 0.5037\n",
      "Epoch 2690: Train Loss = 0.4880, Val Loss = 0.5022\n",
      "Epoch 2700: Train Loss = 0.4865, Val Loss = 0.5008\n",
      "Epoch 2710: Train Loss = 0.4850, Val Loss = 0.4993\n",
      "Epoch 2720: Train Loss = 0.4836, Val Loss = 0.4979\n",
      "Epoch 2730: Train Loss = 0.4822, Val Loss = 0.4964\n",
      "Epoch 2740: Train Loss = 0.4807, Val Loss = 0.4950\n",
      "Epoch 2750: Train Loss = 0.4793, Val Loss = 0.4936\n",
      "Epoch 2760: Train Loss = 0.4779, Val Loss = 0.4922\n",
      "Epoch 2770: Train Loss = 0.4765, Val Loss = 0.4908\n",
      "Epoch 2780: Train Loss = 0.4752, Val Loss = 0.4894\n",
      "Epoch 2790: Train Loss = 0.4738, Val Loss = 0.4881\n",
      "Epoch 2800: Train Loss = 0.4725, Val Loss = 0.4867\n",
      "Epoch 2810: Train Loss = 0.4711, Val Loss = 0.4854\n",
      "Epoch 2820: Train Loss = 0.4698, Val Loss = 0.4841\n",
      "Epoch 2830: Train Loss = 0.4685, Val Loss = 0.4827\n",
      "Epoch 2840: Train Loss = 0.4672, Val Loss = 0.4814\n",
      "Epoch 2850: Train Loss = 0.4659, Val Loss = 0.4801\n",
      "Epoch 2860: Train Loss = 0.4646, Val Loss = 0.4788\n",
      "Epoch 2870: Train Loss = 0.4633, Val Loss = 0.4776\n",
      "Epoch 2880: Train Loss = 0.4621, Val Loss = 0.4763\n",
      "Epoch 2890: Train Loss = 0.4608, Val Loss = 0.4751\n",
      "Epoch 2900: Train Loss = 0.4596, Val Loss = 0.4738\n",
      "Epoch 2910: Train Loss = 0.4584, Val Loss = 0.4726\n",
      "Epoch 2920: Train Loss = 0.4571, Val Loss = 0.4714\n",
      "Epoch 2930: Train Loss = 0.4559, Val Loss = 0.4701\n",
      "Epoch 2940: Train Loss = 0.4547, Val Loss = 0.4689\n",
      "Epoch 2950: Train Loss = 0.4536, Val Loss = 0.4677\n",
      "Epoch 2960: Train Loss = 0.4524, Val Loss = 0.4666\n",
      "Epoch 2970: Train Loss = 0.4512, Val Loss = 0.4654\n",
      "Epoch 2980: Train Loss = 0.4500, Val Loss = 0.4642\n",
      "Epoch 2990: Train Loss = 0.4489, Val Loss = 0.4631\n",
      "Epoch 3000: Train Loss = 0.4478, Val Loss = 0.4619\n",
      "Epoch 3010: Train Loss = 0.4466, Val Loss = 0.4608\n",
      "Epoch 3020: Train Loss = 0.4455, Val Loss = 0.4596\n",
      "Epoch 3030: Train Loss = 0.4444, Val Loss = 0.4585\n",
      "Epoch 3040: Train Loss = 0.4433, Val Loss = 0.4574\n",
      "Epoch 3050: Train Loss = 0.4422, Val Loss = 0.4563\n",
      "Epoch 3060: Train Loss = 0.4411, Val Loss = 0.4552\n",
      "Epoch 3070: Train Loss = 0.4400, Val Loss = 0.4541\n",
      "Epoch 3080: Train Loss = 0.4390, Val Loss = 0.4531\n",
      "Epoch 3090: Train Loss = 0.4379, Val Loss = 0.4520\n",
      "Epoch 3100: Train Loss = 0.4369, Val Loss = 0.4509\n",
      "Epoch 3110: Train Loss = 0.4358, Val Loss = 0.4499\n",
      "Epoch 3120: Train Loss = 0.4348, Val Loss = 0.4488\n",
      "Epoch 3130: Train Loss = 0.4338, Val Loss = 0.4478\n",
      "Epoch 3140: Train Loss = 0.4327, Val Loss = 0.4468\n",
      "Epoch 3150: Train Loss = 0.4317, Val Loss = 0.4457\n",
      "Epoch 3160: Train Loss = 0.4307, Val Loss = 0.4447\n",
      "Epoch 3170: Train Loss = 0.4297, Val Loss = 0.4437\n",
      "Epoch 3180: Train Loss = 0.4288, Val Loss = 0.4427\n",
      "Epoch 3190: Train Loss = 0.4278, Val Loss = 0.4417\n",
      "Epoch 3200: Train Loss = 0.4268, Val Loss = 0.4408\n",
      "Epoch 3210: Train Loss = 0.4258, Val Loss = 0.4398\n",
      "Epoch 3220: Train Loss = 0.4249, Val Loss = 0.4388\n",
      "Epoch 3230: Train Loss = 0.4239, Val Loss = 0.4378\n",
      "Epoch 3240: Train Loss = 0.4230, Val Loss = 0.4369\n",
      "Epoch 3250: Train Loss = 0.4221, Val Loss = 0.4359\n",
      "Epoch 3260: Train Loss = 0.4211, Val Loss = 0.4350\n",
      "Epoch 3270: Train Loss = 0.4202, Val Loss = 0.4341\n",
      "Epoch 3280: Train Loss = 0.4193, Val Loss = 0.4331\n",
      "Epoch 3290: Train Loss = 0.4184, Val Loss = 0.4322\n",
      "Epoch 3300: Train Loss = 0.4175, Val Loss = 0.4313\n",
      "Epoch 3310: Train Loss = 0.4166, Val Loss = 0.4304\n",
      "Epoch 3320: Train Loss = 0.4157, Val Loss = 0.4295\n",
      "Epoch 3330: Train Loss = 0.4148, Val Loss = 0.4286\n",
      "Epoch 3340: Train Loss = 0.4139, Val Loss = 0.4277\n",
      "Epoch 3350: Train Loss = 0.4131, Val Loss = 0.4268\n",
      "Epoch 3360: Train Loss = 0.4122, Val Loss = 0.4259\n",
      "Epoch 3370: Train Loss = 0.4114, Val Loss = 0.4251\n",
      "Epoch 3380: Train Loss = 0.4105, Val Loss = 0.4242\n",
      "Epoch 3390: Train Loss = 0.4097, Val Loss = 0.4233\n",
      "Epoch 3400: Train Loss = 0.4088, Val Loss = 0.4225\n",
      "Epoch 3410: Train Loss = 0.4080, Val Loss = 0.4216\n",
      "Epoch 3420: Train Loss = 0.4071, Val Loss = 0.4208\n",
      "Epoch 3430: Train Loss = 0.4063, Val Loss = 0.4199\n",
      "Epoch 3440: Train Loss = 0.4055, Val Loss = 0.4191\n",
      "Epoch 3450: Train Loss = 0.4047, Val Loss = 0.4183\n",
      "Epoch 3460: Train Loss = 0.4039, Val Loss = 0.4174\n",
      "Epoch 3470: Train Loss = 0.4031, Val Loss = 0.4166\n",
      "Epoch 3480: Train Loss = 0.4023, Val Loss = 0.4158\n",
      "Epoch 3490: Train Loss = 0.4015, Val Loss = 0.4150\n",
      "Epoch 3500: Train Loss = 0.4007, Val Loss = 0.4142\n",
      "Epoch 3510: Train Loss = 0.3999, Val Loss = 0.4134\n",
      "Epoch 3520: Train Loss = 0.3991, Val Loss = 0.4126\n",
      "Epoch 3530: Train Loss = 0.3984, Val Loss = 0.4118\n",
      "Epoch 3540: Train Loss = 0.3976, Val Loss = 0.4110\n",
      "Epoch 3550: Train Loss = 0.3968, Val Loss = 0.4102\n",
      "Epoch 3560: Train Loss = 0.3961, Val Loss = 0.4094\n",
      "Epoch 3570: Train Loss = 0.3953, Val Loss = 0.4087\n",
      "Epoch 3580: Train Loss = 0.3946, Val Loss = 0.4079\n",
      "Epoch 3590: Train Loss = 0.3938, Val Loss = 0.4071\n",
      "Epoch 3600: Train Loss = 0.3931, Val Loss = 0.4064\n",
      "Epoch 3610: Train Loss = 0.3924, Val Loss = 0.4056\n",
      "Epoch 3620: Train Loss = 0.3916, Val Loss = 0.4049\n",
      "Epoch 3630: Train Loss = 0.3909, Val Loss = 0.4041\n",
      "Epoch 3640: Train Loss = 0.3902, Val Loss = 0.4034\n",
      "Epoch 3650: Train Loss = 0.3895, Val Loss = 0.4026\n",
      "Epoch 3660: Train Loss = 0.3887, Val Loss = 0.4019\n",
      "Epoch 3670: Train Loss = 0.3880, Val Loss = 0.4012\n",
      "Epoch 3680: Train Loss = 0.3873, Val Loss = 0.4004\n",
      "Epoch 3690: Train Loss = 0.3866, Val Loss = 0.3997\n",
      "Epoch 3700: Train Loss = 0.3859, Val Loss = 0.3990\n",
      "Epoch 3710: Train Loss = 0.3852, Val Loss = 0.3983\n",
      "Epoch 3720: Train Loss = 0.3845, Val Loss = 0.3976\n",
      "Epoch 3730: Train Loss = 0.3839, Val Loss = 0.3969\n",
      "Epoch 3740: Train Loss = 0.3832, Val Loss = 0.3961\n",
      "Epoch 3750: Train Loss = 0.3825, Val Loss = 0.3954\n",
      "Epoch 3760: Train Loss = 0.3818, Val Loss = 0.3947\n",
      "Epoch 3770: Train Loss = 0.3811, Val Loss = 0.3940\n",
      "Epoch 3780: Train Loss = 0.3805, Val Loss = 0.3933\n",
      "Epoch 3790: Train Loss = 0.3798, Val Loss = 0.3927\n",
      "Epoch 3800: Train Loss = 0.3791, Val Loss = 0.3920\n",
      "Epoch 3810: Train Loss = 0.3785, Val Loss = 0.3913\n",
      "Epoch 3820: Train Loss = 0.3778, Val Loss = 0.3906\n",
      "Epoch 3830: Train Loss = 0.3772, Val Loss = 0.3899\n",
      "Epoch 3840: Train Loss = 0.3765, Val Loss = 0.3893\n",
      "Epoch 3850: Train Loss = 0.3759, Val Loss = 0.3886\n",
      "Epoch 3860: Train Loss = 0.3752, Val Loss = 0.3879\n",
      "Epoch 3870: Train Loss = 0.3746, Val Loss = 0.3873\n",
      "Epoch 3880: Train Loss = 0.3739, Val Loss = 0.3866\n",
      "Epoch 3890: Train Loss = 0.3733, Val Loss = 0.3859\n",
      "Epoch 3900: Train Loss = 0.3727, Val Loss = 0.3853\n",
      "Epoch 3910: Train Loss = 0.3720, Val Loss = 0.3846\n",
      "Epoch 3920: Train Loss = 0.3714, Val Loss = 0.3840\n",
      "Epoch 3930: Train Loss = 0.3708, Val Loss = 0.3833\n",
      "Epoch 3940: Train Loss = 0.3702, Val Loss = 0.3827\n",
      "Epoch 3950: Train Loss = 0.3696, Val Loss = 0.3820\n",
      "Epoch 3960: Train Loss = 0.3689, Val Loss = 0.3814\n",
      "Epoch 3970: Train Loss = 0.3683, Val Loss = 0.3808\n",
      "Epoch 3980: Train Loss = 0.3677, Val Loss = 0.3801\n",
      "Epoch 3990: Train Loss = 0.3671, Val Loss = 0.3795\n",
      "Epoch 4000: Train Loss = 0.3665, Val Loss = 0.3789\n",
      "Epoch 4010: Train Loss = 0.3659, Val Loss = 0.3782\n",
      "Epoch 4020: Train Loss = 0.3653, Val Loss = 0.3776\n",
      "Epoch 4030: Train Loss = 0.3647, Val Loss = 0.3770\n",
      "Epoch 4040: Train Loss = 0.3641, Val Loss = 0.3764\n",
      "Epoch 4050: Train Loss = 0.3635, Val Loss = 0.3758\n",
      "Epoch 4060: Train Loss = 0.3629, Val Loss = 0.3751\n",
      "Epoch 4070: Train Loss = 0.3624, Val Loss = 0.3745\n",
      "Epoch 4080: Train Loss = 0.3618, Val Loss = 0.3739\n",
      "Epoch 4090: Train Loss = 0.3612, Val Loss = 0.3733\n",
      "Epoch 4100: Train Loss = 0.3606, Val Loss = 0.3727\n",
      "Epoch 4110: Train Loss = 0.3600, Val Loss = 0.3721\n",
      "Epoch 4120: Train Loss = 0.3595, Val Loss = 0.3715\n",
      "Epoch 4130: Train Loss = 0.3589, Val Loss = 0.3709\n",
      "Epoch 4140: Train Loss = 0.3583, Val Loss = 0.3703\n",
      "Epoch 4150: Train Loss = 0.3578, Val Loss = 0.3697\n",
      "Epoch 4160: Train Loss = 0.3572, Val Loss = 0.3691\n",
      "Epoch 4170: Train Loss = 0.3566, Val Loss = 0.3685\n",
      "Epoch 4180: Train Loss = 0.3561, Val Loss = 0.3680\n",
      "Epoch 4190: Train Loss = 0.3555, Val Loss = 0.3674\n",
      "Epoch 4200: Train Loss = 0.3550, Val Loss = 0.3668\n",
      "Epoch 4210: Train Loss = 0.3544, Val Loss = 0.3662\n",
      "Epoch 4220: Train Loss = 0.3539, Val Loss = 0.3656\n",
      "Epoch 4230: Train Loss = 0.3533, Val Loss = 0.3651\n",
      "Epoch 4240: Train Loss = 0.3528, Val Loss = 0.3645\n",
      "Epoch 4250: Train Loss = 0.3522, Val Loss = 0.3639\n",
      "Epoch 4260: Train Loss = 0.3517, Val Loss = 0.3634\n",
      "Epoch 4270: Train Loss = 0.3511, Val Loss = 0.3628\n",
      "Epoch 4280: Train Loss = 0.3506, Val Loss = 0.3622\n",
      "Epoch 4290: Train Loss = 0.3501, Val Loss = 0.3617\n",
      "Epoch 4300: Train Loss = 0.3495, Val Loss = 0.3611\n",
      "Epoch 4310: Train Loss = 0.3490, Val Loss = 0.3605\n",
      "Epoch 4320: Train Loss = 0.3485, Val Loss = 0.3600\n",
      "Epoch 4330: Train Loss = 0.3480, Val Loss = 0.3594\n",
      "Epoch 4340: Train Loss = 0.3474, Val Loss = 0.3589\n",
      "Epoch 4350: Train Loss = 0.3469, Val Loss = 0.3583\n",
      "Epoch 4360: Train Loss = 0.3464, Val Loss = 0.3578\n",
      "Epoch 4370: Train Loss = 0.3459, Val Loss = 0.3572\n",
      "Epoch 4380: Train Loss = 0.3454, Val Loss = 0.3567\n",
      "Epoch 4390: Train Loss = 0.3448, Val Loss = 0.3562\n",
      "Epoch 4400: Train Loss = 0.3443, Val Loss = 0.3556\n",
      "Epoch 4410: Train Loss = 0.3438, Val Loss = 0.3551\n",
      "Epoch 4420: Train Loss = 0.3433, Val Loss = 0.3546\n",
      "Epoch 4430: Train Loss = 0.3428, Val Loss = 0.3540\n",
      "Epoch 4440: Train Loss = 0.3423, Val Loss = 0.3535\n",
      "Epoch 4450: Train Loss = 0.3418, Val Loss = 0.3530\n",
      "Epoch 4460: Train Loss = 0.3413, Val Loss = 0.3524\n",
      "Epoch 4470: Train Loss = 0.3408, Val Loss = 0.3519\n",
      "Epoch 4480: Train Loss = 0.3403, Val Loss = 0.3514\n",
      "Epoch 4490: Train Loss = 0.3398, Val Loss = 0.3509\n",
      "Epoch 4500: Train Loss = 0.3393, Val Loss = 0.3503\n",
      "Epoch 4510: Train Loss = 0.3388, Val Loss = 0.3498\n",
      "Epoch 4520: Train Loss = 0.3383, Val Loss = 0.3493\n",
      "Epoch 4530: Train Loss = 0.3378, Val Loss = 0.3488\n",
      "Epoch 4540: Train Loss = 0.3374, Val Loss = 0.3483\n",
      "Epoch 4550: Train Loss = 0.3369, Val Loss = 0.3478\n",
      "Epoch 4560: Train Loss = 0.3364, Val Loss = 0.3473\n",
      "Epoch 4570: Train Loss = 0.3359, Val Loss = 0.3468\n",
      "Epoch 4580: Train Loss = 0.3354, Val Loss = 0.3463\n",
      "Epoch 4590: Train Loss = 0.3350, Val Loss = 0.3458\n",
      "Epoch 4600: Train Loss = 0.3345, Val Loss = 0.3453\n",
      "Epoch 4610: Train Loss = 0.3340, Val Loss = 0.3448\n",
      "Epoch 4620: Train Loss = 0.3335, Val Loss = 0.3443\n",
      "Epoch 4630: Train Loss = 0.3331, Val Loss = 0.3438\n",
      "Epoch 4640: Train Loss = 0.3326, Val Loss = 0.3433\n",
      "Epoch 4650: Train Loss = 0.3322, Val Loss = 0.3428\n",
      "Epoch 4660: Train Loss = 0.3317, Val Loss = 0.3423\n",
      "Epoch 4670: Train Loss = 0.3312, Val Loss = 0.3418\n",
      "Epoch 4680: Train Loss = 0.3308, Val Loss = 0.3414\n",
      "Epoch 4690: Train Loss = 0.3303, Val Loss = 0.3409\n",
      "Epoch 4700: Train Loss = 0.3299, Val Loss = 0.3404\n",
      "Epoch 4710: Train Loss = 0.3294, Val Loss = 0.3399\n",
      "Epoch 4720: Train Loss = 0.3290, Val Loss = 0.3394\n",
      "Epoch 4730: Train Loss = 0.3285, Val Loss = 0.3390\n",
      "Epoch 4740: Train Loss = 0.3281, Val Loss = 0.3385\n",
      "Epoch 4750: Train Loss = 0.3276, Val Loss = 0.3380\n",
      "Epoch 4760: Train Loss = 0.3272, Val Loss = 0.3376\n",
      "Epoch 4770: Train Loss = 0.3267, Val Loss = 0.3371\n",
      "Epoch 4780: Train Loss = 0.3263, Val Loss = 0.3366\n",
      "Epoch 4790: Train Loss = 0.3258, Val Loss = 0.3362\n",
      "Epoch 4800: Train Loss = 0.3254, Val Loss = 0.3357\n",
      "Epoch 4810: Train Loss = 0.3250, Val Loss = 0.3352\n",
      "Epoch 4820: Train Loss = 0.3245, Val Loss = 0.3348\n",
      "Epoch 4830: Train Loss = 0.3241, Val Loss = 0.3343\n",
      "Epoch 4840: Train Loss = 0.3237, Val Loss = 0.3339\n",
      "Epoch 4850: Train Loss = 0.3232, Val Loss = 0.3334\n",
      "Epoch 4860: Train Loss = 0.3228, Val Loss = 0.3330\n",
      "Epoch 4870: Train Loss = 0.3224, Val Loss = 0.3325\n",
      "Epoch 4880: Train Loss = 0.3220, Val Loss = 0.3321\n",
      "Epoch 4890: Train Loss = 0.3215, Val Loss = 0.3316\n",
      "Epoch 4900: Train Loss = 0.3211, Val Loss = 0.3312\n",
      "Epoch 4910: Train Loss = 0.3207, Val Loss = 0.3308\n",
      "Epoch 4920: Train Loss = 0.3203, Val Loss = 0.3303\n",
      "Epoch 4930: Train Loss = 0.3199, Val Loss = 0.3299\n",
      "Epoch 4940: Train Loss = 0.3195, Val Loss = 0.3295\n",
      "Epoch 4950: Train Loss = 0.3191, Val Loss = 0.3290\n",
      "Epoch 4960: Train Loss = 0.3186, Val Loss = 0.3286\n",
      "Epoch 4970: Train Loss = 0.3182, Val Loss = 0.3282\n",
      "Epoch 4980: Train Loss = 0.3178, Val Loss = 0.3277\n",
      "Epoch 4990: Train Loss = 0.3174, Val Loss = 0.3273\n",
      "Epoch 5000: Train Loss = 0.3170, Val Loss = 0.3269\n",
      "Epoch 5010: Train Loss = 0.3166, Val Loss = 0.3265\n",
      "Epoch 5020: Train Loss = 0.3162, Val Loss = 0.3260\n",
      "Epoch 5030: Train Loss = 0.3158, Val Loss = 0.3256\n",
      "Epoch 5040: Train Loss = 0.3154, Val Loss = 0.3252\n",
      "Epoch 5050: Train Loss = 0.3150, Val Loss = 0.3248\n",
      "Epoch 5060: Train Loss = 0.3146, Val Loss = 0.3244\n",
      "Epoch 5070: Train Loss = 0.3143, Val Loss = 0.3240\n",
      "Epoch 5080: Train Loss = 0.3139, Val Loss = 0.3236\n",
      "Epoch 5090: Train Loss = 0.3135, Val Loss = 0.3232\n",
      "Epoch 5100: Train Loss = 0.3131, Val Loss = 0.3228\n",
      "Epoch 5110: Train Loss = 0.3127, Val Loss = 0.3224\n",
      "Epoch 5120: Train Loss = 0.3123, Val Loss = 0.3220\n",
      "Epoch 5130: Train Loss = 0.3119, Val Loss = 0.3216\n",
      "Epoch 5140: Train Loss = 0.3116, Val Loss = 0.3212\n",
      "Epoch 5150: Train Loss = 0.3112, Val Loss = 0.3208\n",
      "Epoch 5160: Train Loss = 0.3108, Val Loss = 0.3204\n",
      "Epoch 5170: Train Loss = 0.3104, Val Loss = 0.3200\n",
      "Epoch 5180: Train Loss = 0.3101, Val Loss = 0.3196\n",
      "Epoch 5190: Train Loss = 0.3097, Val Loss = 0.3192\n",
      "Epoch 5200: Train Loss = 0.3093, Val Loss = 0.3188\n",
      "Epoch 5210: Train Loss = 0.3090, Val Loss = 0.3184\n",
      "Epoch 5220: Train Loss = 0.3086, Val Loss = 0.3180\n",
      "Epoch 5230: Train Loss = 0.3082, Val Loss = 0.3176\n",
      "Epoch 5240: Train Loss = 0.3086, Val Loss = 0.3182\n",
      "Epoch 5250: Train Loss = 0.6559, Val Loss = 0.9704\n",
      "Epoch 5260: Train Loss = 3.8042, Val Loss = 0.3421\n",
      "Epoch 5270: Train Loss = 0.6198, Val Loss = 0.9842\n",
      "Epoch 5280: Train Loss = 0.9279, Val Loss = 1.6022\n",
      "Epoch 5290: Train Loss = 0.7690, Val Loss = 0.4412\n",
      "Epoch 5300: Train Loss = 0.3121, Val Loss = 0.3561\n",
      "Epoch 5310: Train Loss = 0.3388, Val Loss = 0.3693\n",
      "Epoch 5320: Train Loss = 0.3274, Val Loss = 0.3227\n",
      "Epoch 5330: Train Loss = 0.3082, Val Loss = 0.3141\n",
      "Epoch 5340: Train Loss = 0.3046, Val Loss = 0.3149\n",
      "Epoch 5350: Train Loss = 0.3044, Val Loss = 0.3144\n",
      "Epoch 5360: Train Loss = 0.3041, Val Loss = 0.3136\n",
      "Epoch 5370: Train Loss = 0.3037, Val Loss = 0.3130\n",
      "Epoch 5380: Train Loss = 0.3034, Val Loss = 0.3125\n",
      "Epoch 5390: Train Loss = 0.3030, Val Loss = 0.3122\n",
      "Epoch 5400: Train Loss = 0.3027, Val Loss = 0.3118\n",
      "Epoch 5410: Train Loss = 0.3024, Val Loss = 0.3115\n",
      "Epoch 5420: Train Loss = 0.3021, Val Loss = 0.3111\n",
      "Epoch 5430: Train Loss = 0.3018, Val Loss = 0.3108\n",
      "Epoch 5440: Train Loss = 0.3015, Val Loss = 0.3105\n",
      "Epoch 5450: Train Loss = 0.3012, Val Loss = 0.3102\n",
      "Epoch 5460: Train Loss = 0.3009, Val Loss = 0.3098\n",
      "Epoch 5470: Train Loss = 0.3006, Val Loss = 0.3095\n",
      "Epoch 5480: Train Loss = 0.3003, Val Loss = 0.3092\n",
      "Epoch 5490: Train Loss = 0.3000, Val Loss = 0.3089\n",
      "Epoch 5500: Train Loss = 0.2997, Val Loss = 0.3086\n",
      "Epoch 5510: Train Loss = 0.2994, Val Loss = 0.3083\n",
      "Epoch 5520: Train Loss = 0.2991, Val Loss = 0.3080\n",
      "Epoch 5530: Train Loss = 0.2988, Val Loss = 0.3077\n",
      "Epoch 5540: Train Loss = 0.2985, Val Loss = 0.3074\n",
      "Epoch 5550: Train Loss = 0.2982, Val Loss = 0.3070\n",
      "Epoch 5560: Train Loss = 0.2979, Val Loss = 0.3067\n",
      "Epoch 5570: Train Loss = 0.2976, Val Loss = 0.3064\n",
      "Epoch 5580: Train Loss = 0.2973, Val Loss = 0.3061\n",
      "Epoch 5590: Train Loss = 0.2970, Val Loss = 0.3058\n",
      "Epoch 5600: Train Loss = 0.2967, Val Loss = 0.3055\n",
      "Epoch 5610: Train Loss = 0.2965, Val Loss = 0.3052\n",
      "Epoch 5620: Train Loss = 0.2962, Val Loss = 0.3050\n",
      "Epoch 5630: Train Loss = 0.2964, Val Loss = 0.3059\n",
      "Epoch 5640: Train Loss = 0.4521, Val Loss = 0.5976\n",
      "Epoch 5650: Train Loss = 14.1925, Val Loss = 7.6722\n",
      "Epoch 5660: Train Loss = 4.5855, Val Loss = 3.0795\n",
      "Epoch 5670: Train Loss = 1.4576, Val Loss = 0.4985\n",
      "Epoch 5680: Train Loss = 0.3535, Val Loss = 0.3588\n",
      "Epoch 5690: Train Loss = 0.3182, Val Loss = 0.4264\n",
      "Epoch 5700: Train Loss = 0.3393, Val Loss = 0.3589\n",
      "Epoch 5710: Train Loss = 0.3170, Val Loss = 0.3162\n",
      "Epoch 5720: Train Loss = 0.3015, Val Loss = 0.3045\n",
      "Epoch 5730: Train Loss = 0.2958, Val Loss = 0.3022\n",
      "Epoch 5740: Train Loss = 0.2939, Val Loss = 0.3017\n",
      "Epoch 5750: Train Loss = 0.2931, Val Loss = 0.3014\n",
      "Epoch 5760: Train Loss = 0.2927, Val Loss = 0.3011\n",
      "Epoch 5770: Train Loss = 0.2923, Val Loss = 0.3008\n",
      "Epoch 5780: Train Loss = 0.2921, Val Loss = 0.3006\n",
      "Epoch 5790: Train Loss = 0.2918, Val Loss = 0.3003\n",
      "Epoch 5800: Train Loss = 0.2916, Val Loss = 0.3001\n",
      "Epoch 5810: Train Loss = 0.2913, Val Loss = 0.2998\n",
      "Epoch 5820: Train Loss = 0.2911, Val Loss = 0.2996\n",
      "Epoch 5830: Train Loss = 0.2908, Val Loss = 0.2993\n",
      "Epoch 5840: Train Loss = 0.2906, Val Loss = 0.2991\n",
      "Epoch 5850: Train Loss = 0.2904, Val Loss = 0.2988\n",
      "Epoch 5860: Train Loss = 0.2901, Val Loss = 0.2986\n",
      "Epoch 5870: Train Loss = 0.2899, Val Loss = 0.2983\n",
      "Epoch 5880: Train Loss = 0.2896, Val Loss = 0.2981\n",
      "Epoch 5890: Train Loss = 0.2894, Val Loss = 0.2978\n",
      "Epoch 5900: Train Loss = 0.2892, Val Loss = 0.2976\n",
      "Epoch 5910: Train Loss = 0.2889, Val Loss = 0.2973\n",
      "Epoch 5920: Train Loss = 0.2887, Val Loss = 0.2971\n",
      "Epoch 5930: Train Loss = 0.2885, Val Loss = 0.2968\n",
      "Epoch 5940: Train Loss = 0.2882, Val Loss = 0.2966\n",
      "Epoch 5950: Train Loss = 0.2880, Val Loss = 0.2964\n",
      "Epoch 5960: Train Loss = 0.2878, Val Loss = 0.2961\n",
      "Epoch 5970: Train Loss = 0.2875, Val Loss = 0.2959\n",
      "Epoch 5980: Train Loss = 0.2873, Val Loss = 0.2956\n",
      "Epoch 5990: Train Loss = 0.2871, Val Loss = 0.2954\n",
      "Epoch 6000: Train Loss = 0.2868, Val Loss = 0.2951\n",
      "Epoch 6010: Train Loss = 0.2907, Val Loss = 0.3017\n",
      "Epoch 6020: Train Loss = 3.5725, Val Loss = 6.4630\n",
      "Epoch 6030: Train Loss = 9.7842, Val Loss = 3.5337\n",
      "Epoch 6040: Train Loss = 0.4701, Val Loss = 1.0573\n",
      "Epoch 6050: Train Loss = 1.3603, Val Loss = 1.0466\n",
      "Epoch 6060: Train Loss = 0.3012, Val Loss = 0.4112\n",
      "Epoch 6070: Train Loss = 0.4226, Val Loss = 0.3875\n",
      "Epoch 6080: Train Loss = 0.2895, Val Loss = 0.3017\n",
      "Epoch 6090: Train Loss = 0.2986, Val Loss = 0.3069\n",
      "Epoch 6100: Train Loss = 0.2883, Val Loss = 0.2930\n",
      "Epoch 6110: Train Loss = 0.2847, Val Loss = 0.2947\n",
      "Epoch 6120: Train Loss = 0.2851, Val Loss = 0.2935\n",
      "Epoch 6130: Train Loss = 0.2844, Val Loss = 0.2925\n",
      "Epoch 6140: Train Loss = 0.2840, Val Loss = 0.2921\n",
      "Epoch 6150: Train Loss = 0.2838, Val Loss = 0.2919\n",
      "Epoch 6160: Train Loss = 0.2836, Val Loss = 0.2917\n",
      "Epoch 6170: Train Loss = 0.2834, Val Loss = 0.2915\n",
      "Epoch 6180: Train Loss = 0.2832, Val Loss = 0.2914\n",
      "Epoch 6190: Train Loss = 0.2830, Val Loss = 0.2912\n",
      "Epoch 6200: Train Loss = 0.2828, Val Loss = 0.2910\n",
      "Epoch 6210: Train Loss = 0.2826, Val Loss = 0.2908\n",
      "Epoch 6220: Train Loss = 0.2824, Val Loss = 0.2906\n",
      "Epoch 6230: Train Loss = 0.2822, Val Loss = 0.2904\n",
      "Epoch 6240: Train Loss = 0.2820, Val Loss = 0.2902\n",
      "Epoch 6250: Train Loss = 0.2819, Val Loss = 0.2900\n",
      "Epoch 6260: Train Loss = 0.2817, Val Loss = 0.2898\n",
      "Epoch 6270: Train Loss = 0.2815, Val Loss = 0.2896\n",
      "Epoch 6280: Train Loss = 0.2813, Val Loss = 0.2894\n",
      "Epoch 6290: Train Loss = 0.2811, Val Loss = 0.2892\n",
      "Epoch 6300: Train Loss = 0.2809, Val Loss = 0.2890\n",
      "Epoch 6310: Train Loss = 0.2807, Val Loss = 0.2888\n",
      "Epoch 6320: Train Loss = 0.2805, Val Loss = 0.2886\n",
      "Epoch 6330: Train Loss = 0.2803, Val Loss = 0.2885\n",
      "Epoch 6340: Train Loss = 0.2802, Val Loss = 0.2883\n",
      "Epoch 6350: Train Loss = 0.2800, Val Loss = 0.2881\n",
      "Epoch 6360: Train Loss = 0.2798, Val Loss = 0.2879\n",
      "Epoch 6370: Train Loss = 0.2796, Val Loss = 0.2877\n",
      "Epoch 6380: Train Loss = 0.2794, Val Loss = 0.2875\n",
      "Epoch 6390: Train Loss = 0.2792, Val Loss = 0.2873\n",
      "Epoch 6400: Train Loss = 0.2791, Val Loss = 0.2871\n",
      "Epoch 6410: Train Loss = 0.2789, Val Loss = 0.2870\n",
      "Epoch 6420: Train Loss = 0.2787, Val Loss = 0.2868\n",
      "Epoch 6430: Train Loss = 0.2786, Val Loss = 0.2868\n",
      "Epoch 6440: Train Loss = 0.2898, Val Loss = 0.3085\n",
      "Epoch 6450: Train Loss = 3.9069, Val Loss = 6.4359\n",
      "Epoch 6460: Train Loss = 7.1213, Val Loss = 4.8585\n",
      "Epoch 6470: Train Loss = 2.5572, Val Loss = 1.4170\n",
      "Epoch 6480: Train Loss = 0.8531, Val Loss = 0.3584\n",
      "Epoch 6490: Train Loss = 0.3402, Val Loss = 0.2956\n",
      "Epoch 6500: Train Loss = 0.2776, Val Loss = 0.3181\n",
      "Epoch 6510: Train Loss = 0.2797, Val Loss = 0.3077\n",
      "Epoch 6520: Train Loss = 0.2794, Val Loss = 0.2954\n",
      "Epoch 6530: Train Loss = 0.2778, Val Loss = 0.2890\n",
      "Epoch 6540: Train Loss = 0.2769, Val Loss = 0.2861\n",
      "Epoch 6550: Train Loss = 0.2765, Val Loss = 0.2849\n",
      "Epoch 6560: Train Loss = 0.2764, Val Loss = 0.2844\n",
      "Epoch 6570: Train Loss = 0.2763, Val Loss = 0.2842\n",
      "Epoch 6580: Train Loss = 0.2761, Val Loss = 0.2840\n",
      "Epoch 6590: Train Loss = 0.2759, Val Loss = 0.2839\n",
      "Epoch 6600: Train Loss = 0.2757, Val Loss = 0.2838\n",
      "Epoch 6610: Train Loss = 0.2756, Val Loss = 0.2836\n",
      "Epoch 6620: Train Loss = 0.2754, Val Loss = 0.2834\n",
      "Epoch 6630: Train Loss = 0.2753, Val Loss = 0.2833\n",
      "Epoch 6640: Train Loss = 0.2751, Val Loss = 0.2831\n",
      "Epoch 6650: Train Loss = 0.2750, Val Loss = 0.2830\n",
      "Epoch 6660: Train Loss = 0.2748, Val Loss = 0.2828\n",
      "Epoch 6670: Train Loss = 0.2746, Val Loss = 0.2827\n",
      "Epoch 6680: Train Loss = 0.2745, Val Loss = 0.2825\n",
      "Epoch 6690: Train Loss = 0.2743, Val Loss = 0.2823\n",
      "Epoch 6700: Train Loss = 0.2742, Val Loss = 0.2822\n",
      "Epoch 6710: Train Loss = 0.2740, Val Loss = 0.2820\n",
      "Epoch 6720: Train Loss = 0.2739, Val Loss = 0.2819\n",
      "Epoch 6730: Train Loss = 0.2737, Val Loss = 0.2817\n",
      "Epoch 6740: Train Loss = 0.2736, Val Loss = 0.2816\n",
      "Epoch 6750: Train Loss = 0.2734, Val Loss = 0.2814\n",
      "Epoch 6760: Train Loss = 0.2733, Val Loss = 0.2813\n",
      "Epoch 6770: Train Loss = 0.2731, Val Loss = 0.2811\n",
      "Epoch 6780: Train Loss = 0.2731, Val Loss = 0.2814\n",
      "Epoch 6790: Train Loss = 0.3072, Val Loss = 0.3473\n",
      "Epoch 6800: Train Loss = 11.7180, Val Loss = 15.7174\n",
      "Epoch 6810: Train Loss = 0.2997, Val Loss = 1.9094\n",
      "Epoch 6820: Train Loss = 0.7029, Val Loss = 1.8401\n",
      "Epoch 6830: Train Loss = 0.9191, Val Loss = 0.8011\n",
      "Epoch 6840: Train Loss = 0.4493, Val Loss = 0.3026\n",
      "Epoch 6850: Train Loss = 0.2786, Val Loss = 0.2912\n",
      "Epoch 6860: Train Loss = 0.2752, Val Loss = 0.2981\n",
      "Epoch 6870: Train Loss = 0.2776, Val Loss = 0.2882\n",
      "Epoch 6880: Train Loss = 0.2749, Val Loss = 0.2821\n",
      "Epoch 6890: Train Loss = 0.2728, Val Loss = 0.2800\n",
      "Epoch 6900: Train Loss = 0.2718, Val Loss = 0.2794\n",
      "Epoch 6910: Train Loss = 0.2714, Val Loss = 0.2791\n",
      "Epoch 6920: Train Loss = 0.2711, Val Loss = 0.2790\n",
      "Epoch 6930: Train Loss = 0.2709, Val Loss = 0.2789\n",
      "Epoch 6940: Train Loss = 0.2708, Val Loss = 0.2788\n",
      "Epoch 6950: Train Loss = 0.2707, Val Loss = 0.2787\n",
      "Epoch 6960: Train Loss = 0.2706, Val Loss = 0.2785\n",
      "Epoch 6970: Train Loss = 0.2704, Val Loss = 0.2784\n",
      "Epoch 6980: Train Loss = 0.2703, Val Loss = 0.2783\n",
      "Epoch 6990: Train Loss = 0.2702, Val Loss = 0.2781\n",
      "Epoch 7000: Train Loss = 0.2700, Val Loss = 0.2780\n",
      "Epoch 7010: Train Loss = 0.2699, Val Loss = 0.2779\n",
      "Epoch 7020: Train Loss = 0.2698, Val Loss = 0.2778\n",
      "Epoch 7030: Train Loss = 0.2697, Val Loss = 0.2776\n",
      "Epoch 7040: Train Loss = 0.2695, Val Loss = 0.2775\n",
      "Epoch 7050: Train Loss = 0.2694, Val Loss = 0.2774\n",
      "Epoch 7060: Train Loss = 0.2693, Val Loss = 0.2773\n",
      "Epoch 7070: Train Loss = 0.2691, Val Loss = 0.2771\n",
      "Epoch 7080: Train Loss = 0.2690, Val Loss = 0.2770\n",
      "Epoch 7090: Train Loss = 0.2689, Val Loss = 0.2769\n",
      "Epoch 7100: Train Loss = 0.2688, Val Loss = 0.2768\n",
      "Epoch 7110: Train Loss = 0.2686, Val Loss = 0.2766\n",
      "Epoch 7120: Train Loss = 0.2685, Val Loss = 0.2765\n",
      "Epoch 7130: Train Loss = 0.2684, Val Loss = 0.2764\n",
      "Epoch 7140: Train Loss = 0.2683, Val Loss = 0.2763\n",
      "Epoch 7150: Train Loss = 0.2682, Val Loss = 0.2761\n",
      "Epoch 7160: Train Loss = 0.2710, Val Loss = 0.2803\n",
      "Epoch 7170: Train Loss = 1.7093, Val Loss = 2.9301\n",
      "Epoch 7180: Train Loss = 4.7763, Val Loss = 8.6796\n",
      "Epoch 7190: Train Loss = 3.0381, Val Loss = 2.8592\n",
      "Epoch 7200: Train Loss = 1.0224, Val Loss = 0.3343\n",
      "Epoch 7210: Train Loss = 0.2700, Val Loss = 0.4546\n",
      "Epoch 7220: Train Loss = 0.3742, Val Loss = 0.3890\n",
      "Epoch 7230: Train Loss = 0.3094, Val Loss = 0.2829\n",
      "Epoch 7240: Train Loss = 0.2701, Val Loss = 0.2768\n",
      "Epoch 7250: Train Loss = 0.2673, Val Loss = 0.2793\n",
      "Epoch 7260: Train Loss = 0.2678, Val Loss = 0.2775\n",
      "Epoch 7270: Train Loss = 0.2674, Val Loss = 0.2759\n",
      "Epoch 7280: Train Loss = 0.2669, Val Loss = 0.2752\n",
      "Epoch 7290: Train Loss = 0.2667, Val Loss = 0.2748\n",
      "Epoch 7300: Train Loss = 0.2665, Val Loss = 0.2746\n",
      "Epoch 7310: Train Loss = 0.2664, Val Loss = 0.2744\n",
      "Epoch 7320: Train Loss = 0.2663, Val Loss = 0.2743\n",
      "Epoch 7330: Train Loss = 0.2662, Val Loss = 0.2742\n",
      "Epoch 7340: Train Loss = 0.2661, Val Loss = 0.2741\n",
      "Epoch 7350: Train Loss = 0.2660, Val Loss = 0.2739\n",
      "Epoch 7360: Train Loss = 0.2658, Val Loss = 0.2738\n",
      "Epoch 7370: Train Loss = 0.2657, Val Loss = 0.2737\n",
      "Epoch 7380: Train Loss = 0.2656, Val Loss = 0.2736\n",
      "Epoch 7390: Train Loss = 0.2655, Val Loss = 0.2735\n",
      "Epoch 7400: Train Loss = 0.2654, Val Loss = 0.2734\n",
      "Epoch 7410: Train Loss = 0.2653, Val Loss = 0.2733\n",
      "Epoch 7420: Train Loss = 0.2652, Val Loss = 0.2732\n",
      "Epoch 7430: Train Loss = 0.2651, Val Loss = 0.2731\n",
      "Epoch 7440: Train Loss = 0.2650, Val Loss = 0.2730\n",
      "Epoch 7450: Train Loss = 0.2649, Val Loss = 0.2729\n",
      "Epoch 7460: Train Loss = 0.2648, Val Loss = 0.2728\n",
      "Epoch 7470: Train Loss = 0.2647, Val Loss = 0.2727\n",
      "Epoch 7480: Train Loss = 0.2646, Val Loss = 0.2726\n",
      "Epoch 7490: Train Loss = 0.2645, Val Loss = 0.2725\n",
      "Epoch 7500: Train Loss = 0.2644, Val Loss = 0.2724\n",
      "Epoch 7510: Train Loss = 0.2643, Val Loss = 0.2723\n",
      "Epoch 7520: Train Loss = 0.2642, Val Loss = 0.2722\n",
      "Epoch 7530: Train Loss = 0.2641, Val Loss = 0.2724\n",
      "Epoch 7540: Train Loss = 0.2728, Val Loss = 0.2890\n",
      "Epoch 7550: Train Loss = 2.4613, Val Loss = 4.0462\n",
      "Epoch 7560: Train Loss = 4.2966, Val Loss = 6.3151\n",
      "Epoch 7570: Train Loss = 1.1684, Val Loss = 2.1894\n",
      "Epoch 7580: Train Loss = 0.7463, Val Loss = 0.9808\n",
      "Epoch 7590: Train Loss = 0.4958, Val Loss = 0.5091\n",
      "Epoch 7600: Train Loss = 0.3567, Val Loss = 0.3474\n",
      "Epoch 7610: Train Loss = 0.2972, Val Loss = 0.2971\n",
      "Epoch 7620: Train Loss = 0.2745, Val Loss = 0.2807\n",
      "Epoch 7630: Train Loss = 0.2661, Val Loss = 0.2743\n",
      "Epoch 7640: Train Loss = 0.2634, Val Loss = 0.2717\n",
      "Epoch 7650: Train Loss = 0.2630, Val Loss = 0.2710\n",
      "Epoch 7660: Train Loss = 0.2630, Val Loss = 0.2710\n",
      "Epoch 7670: Train Loss = 0.2629, Val Loss = 0.2710\n",
      "Epoch 7680: Train Loss = 0.2627, Val Loss = 0.2708\n",
      "Epoch 7690: Train Loss = 0.2626, Val Loss = 0.2706\n",
      "Epoch 7700: Train Loss = 0.2625, Val Loss = 0.2706\n",
      "Epoch 7710: Train Loss = 0.2624, Val Loss = 0.2705\n",
      "Epoch 7720: Train Loss = 0.2624, Val Loss = 0.2704\n",
      "Epoch 7730: Train Loss = 0.2623, Val Loss = 0.2703\n",
      "Epoch 7740: Train Loss = 0.2622, Val Loss = 0.2702\n",
      "Epoch 7750: Train Loss = 0.2621, Val Loss = 0.2701\n",
      "Epoch 7760: Train Loss = 0.2620, Val Loss = 0.2701\n",
      "Epoch 7770: Train Loss = 0.2619, Val Loss = 0.2700\n",
      "Epoch 7780: Train Loss = 0.2618, Val Loss = 0.2699\n",
      "Epoch 7790: Train Loss = 0.2617, Val Loss = 0.2698\n",
      "Epoch 7800: Train Loss = 0.2617, Val Loss = 0.2697\n",
      "Epoch 7810: Train Loss = 0.2616, Val Loss = 0.2696\n",
      "Epoch 7820: Train Loss = 0.2615, Val Loss = 0.2696\n",
      "Epoch 7830: Train Loss = 0.2614, Val Loss = 0.2695\n",
      "Epoch 7840: Train Loss = 0.2613, Val Loss = 0.2694\n",
      "Epoch 7850: Train Loss = 0.2612, Val Loss = 0.2693\n",
      "Epoch 7860: Train Loss = 0.2616, Val Loss = 0.2705\n",
      "Epoch 7870: Train Loss = 0.3954, Val Loss = 0.5207\n",
      "Epoch 7880: Train Loss = 14.8300, Val Loss = 10.0003\n",
      "Epoch 7890: Train Loss = 3.8439, Val Loss = 4.0001\n",
      "Epoch 7900: Train Loss = 1.7423, Val Loss = 1.0574\n",
      "Epoch 7910: Train Loss = 0.5980, Val Loss = 0.2992\n",
      "Epoch 7920: Train Loss = 0.2824, Val Loss = 0.2842\n",
      "Epoch 7930: Train Loss = 0.2617, Val Loss = 0.2964\n",
      "Epoch 7940: Train Loss = 0.2656, Val Loss = 0.2839\n",
      "Epoch 7950: Train Loss = 0.2639, Val Loss = 0.2743\n",
      "Epoch 7960: Train Loss = 0.2618, Val Loss = 0.2702\n",
      "Epoch 7970: Train Loss = 0.2607, Val Loss = 0.2688\n",
      "Epoch 7980: Train Loss = 0.2603, Val Loss = 0.2683\n",
      "Epoch 7990: Train Loss = 0.2601, Val Loss = 0.2682\n",
      "Epoch 8000: Train Loss = 0.2601, Val Loss = 0.2682\n",
      "Epoch 8010: Train Loss = 0.2600, Val Loss = 0.2681\n",
      "Epoch 8020: Train Loss = 0.2599, Val Loss = 0.2681\n",
      "Epoch 8030: Train Loss = 0.2598, Val Loss = 0.2679\n",
      "Epoch 8040: Train Loss = 0.2598, Val Loss = 0.2679\n",
      "Epoch 8050: Train Loss = 0.2597, Val Loss = 0.2678\n",
      "Epoch 8060: Train Loss = 0.2596, Val Loss = 0.2677\n",
      "Epoch 8070: Train Loss = 0.2595, Val Loss = 0.2677\n",
      "Epoch 8080: Train Loss = 0.2595, Val Loss = 0.2676\n",
      "Epoch 8090: Train Loss = 0.2594, Val Loss = 0.2675\n",
      "Epoch 8100: Train Loss = 0.2593, Val Loss = 0.2674\n",
      "Epoch 8110: Train Loss = 0.2592, Val Loss = 0.2674\n",
      "Epoch 8120: Train Loss = 0.2592, Val Loss = 0.2673\n",
      "Epoch 8130: Train Loss = 0.2591, Val Loss = 0.2672\n",
      "Epoch 8140: Train Loss = 0.2590, Val Loss = 0.2672\n",
      "Epoch 8150: Train Loss = 0.2590, Val Loss = 0.2671\n",
      "Epoch 8160: Train Loss = 0.2589, Val Loss = 0.2670\n",
      "Epoch 8170: Train Loss = 0.2588, Val Loss = 0.2669\n",
      "Epoch 8180: Train Loss = 0.2587, Val Loss = 0.2669\n",
      "Epoch 8190: Train Loss = 0.2587, Val Loss = 0.2668\n",
      "Epoch 8200: Train Loss = 0.2586, Val Loss = 0.2669\n",
      "Epoch 8210: Train Loss = 0.2611, Val Loss = 0.2722\n",
      "Epoch 8220: Train Loss = 0.9020, Val Loss = 1.4245\n",
      "Epoch 8230: Train Loss = 1.0484, Val Loss = 0.7316\n",
      "Epoch 8240: Train Loss = 1.2851, Val Loss = 0.2666\n",
      "Epoch 8250: Train Loss = 0.4018, Val Loss = 0.3324\n",
      "Epoch 8260: Train Loss = 0.2593, Val Loss = 0.3667\n",
      "Epoch 8270: Train Loss = 0.2635, Val Loss = 0.3284\n",
      "Epoch 8280: Train Loss = 0.2634, Val Loss = 0.2922\n",
      "Epoch 8290: Train Loss = 0.2599, Val Loss = 0.2745\n",
      "Epoch 8300: Train Loss = 0.2582, Val Loss = 0.2679\n",
      "Epoch 8310: Train Loss = 0.2579, Val Loss = 0.2661\n",
      "Epoch 8320: Train Loss = 0.2581, Val Loss = 0.2660\n",
      "Epoch 8330: Train Loss = 0.2580, Val Loss = 0.2662\n",
      "Epoch 8340: Train Loss = 0.2578, Val Loss = 0.2661\n",
      "Epoch 8350: Train Loss = 0.2576, Val Loss = 0.2659\n",
      "Epoch 8360: Train Loss = 0.2576, Val Loss = 0.2657\n",
      "Epoch 8370: Train Loss = 0.2575, Val Loss = 0.2656\n",
      "Epoch 8380: Train Loss = 0.2574, Val Loss = 0.2656\n",
      "Epoch 8390: Train Loss = 0.2574, Val Loss = 0.2656\n",
      "Epoch 8400: Train Loss = 0.2573, Val Loss = 0.2655\n",
      "Epoch 8410: Train Loss = 0.2573, Val Loss = 0.2654\n",
      "Epoch 8420: Train Loss = 0.2572, Val Loss = 0.2654\n",
      "Epoch 8430: Train Loss = 0.2571, Val Loss = 0.2653\n",
      "Epoch 8440: Train Loss = 0.2571, Val Loss = 0.2652\n",
      "Epoch 8450: Train Loss = 0.2570, Val Loss = 0.2652\n",
      "Epoch 8460: Train Loss = 0.2569, Val Loss = 0.2651\n",
      "Epoch 8470: Train Loss = 0.2569, Val Loss = 0.2651\n",
      "Epoch 8480: Train Loss = 0.2568, Val Loss = 0.2650\n",
      "Epoch 8490: Train Loss = 0.2568, Val Loss = 0.2649\n",
      "Epoch 8500: Train Loss = 0.2567, Val Loss = 0.2649\n",
      "Epoch 8510: Train Loss = 0.2566, Val Loss = 0.2648\n",
      "Epoch 8520: Train Loss = 0.2566, Val Loss = 0.2647\n",
      "Epoch 8530: Train Loss = 0.2569, Val Loss = 0.2649\n",
      "Epoch 8540: Train Loss = 0.3223, Val Loss = 0.3726\n",
      "Epoch 8550: Train Loss = 11.2076, Val Loss = 13.0634\n",
      "Epoch 8560: Train Loss = 0.4401, Val Loss = 0.8453\n",
      "Epoch 8570: Train Loss = 0.3490, Val Loss = 0.4555\n",
      "Epoch 8580: Train Loss = 0.2606, Val Loss = 0.3914\n",
      "Epoch 8590: Train Loss = 0.2565, Val Loss = 0.3270\n",
      "Epoch 8600: Train Loss = 0.2564, Val Loss = 0.2861\n",
      "Epoch 8610: Train Loss = 0.2561, Val Loss = 0.2690\n",
      "Epoch 8620: Train Loss = 0.2569, Val Loss = 0.2644\n",
      "Epoch 8630: Train Loss = 0.2574, Val Loss = 0.2644\n",
      "Epoch 8640: Train Loss = 0.2570, Val Loss = 0.2650\n",
      "Epoch 8650: Train Loss = 0.2562, Val Loss = 0.2648\n",
      "Epoch 8660: Train Loss = 0.2558, Val Loss = 0.2642\n",
      "Epoch 8670: Train Loss = 0.2558, Val Loss = 0.2639\n",
      "Epoch 8680: Train Loss = 0.2557, Val Loss = 0.2639\n",
      "Epoch 8690: Train Loss = 0.2557, Val Loss = 0.2639\n",
      "Epoch 8700: Train Loss = 0.2556, Val Loss = 0.2638\n",
      "Epoch 8710: Train Loss = 0.2555, Val Loss = 0.2637\n",
      "Epoch 8720: Train Loss = 0.2555, Val Loss = 0.2637\n",
      "Epoch 8730: Train Loss = 0.2554, Val Loss = 0.2637\n",
      "Epoch 8740: Train Loss = 0.2554, Val Loss = 0.2636\n",
      "Epoch 8750: Train Loss = 0.2553, Val Loss = 0.2636\n",
      "Epoch 8760: Train Loss = 0.2553, Val Loss = 0.2635\n",
      "Epoch 8770: Train Loss = 0.2552, Val Loss = 0.2635\n",
      "Epoch 8780: Train Loss = 0.2552, Val Loss = 0.2634\n",
      "Epoch 8790: Train Loss = 0.2551, Val Loss = 0.2633\n",
      "Epoch 8800: Train Loss = 0.2551, Val Loss = 0.2633\n",
      "Epoch 8810: Train Loss = 0.2550, Val Loss = 0.2632\n",
      "Epoch 8820: Train Loss = 0.2550, Val Loss = 0.2632\n",
      "Epoch 8830: Train Loss = 0.2549, Val Loss = 0.2631\n",
      "Epoch 8840: Train Loss = 0.2549, Val Loss = 0.2631\n",
      "Epoch 8850: Train Loss = 0.2552, Val Loss = 0.2633\n",
      "Epoch 8860: Train Loss = 0.3705, Val Loss = 0.4638\n",
      "Epoch 8870: Train Loss = 15.2110, Val Loss = 11.5430\n",
      "Epoch 8880: Train Loss = 3.2272, Val Loss = 4.2055\n",
      "Epoch 8890: Train Loss = 1.7167, Val Loss = 1.3035\n",
      "Epoch 8900: Train Loss = 0.7030, Val Loss = 0.3567\n",
      "Epoch 8910: Train Loss = 0.3132, Val Loss = 0.2648\n",
      "Epoch 8920: Train Loss = 0.2555, Val Loss = 0.2815\n",
      "Epoch 8930: Train Loss = 0.2555, Val Loss = 0.2775\n",
      "Epoch 8940: Train Loss = 0.2558, Val Loss = 0.2699\n",
      "Epoch 8950: Train Loss = 0.2550, Val Loss = 0.2656\n",
      "Epoch 8960: Train Loss = 0.2544, Val Loss = 0.2637\n",
      "Epoch 8970: Train Loss = 0.2543, Val Loss = 0.2629\n",
      "Epoch 8980: Train Loss = 0.2542, Val Loss = 0.2625\n",
      "Epoch 8990: Train Loss = 0.2542, Val Loss = 0.2624\n",
      "Epoch 9000: Train Loss = 0.2541, Val Loss = 0.2623\n",
      "Epoch 9010: Train Loss = 0.2541, Val Loss = 0.2623\n",
      "Epoch 9020: Train Loss = 0.2540, Val Loss = 0.2623\n",
      "Epoch 9030: Train Loss = 0.2540, Val Loss = 0.2623\n",
      "Epoch 9040: Train Loss = 0.2540, Val Loss = 0.2622\n",
      "Epoch 9050: Train Loss = 0.2539, Val Loss = 0.2622\n",
      "Epoch 9060: Train Loss = 0.2539, Val Loss = 0.2621\n",
      "Epoch 9070: Train Loss = 0.2538, Val Loss = 0.2621\n",
      "Epoch 9080: Train Loss = 0.2538, Val Loss = 0.2620\n",
      "Epoch 9090: Train Loss = 0.2537, Val Loss = 0.2620\n",
      "Epoch 9100: Train Loss = 0.2537, Val Loss = 0.2620\n",
      "Epoch 9110: Train Loss = 0.2536, Val Loss = 0.2619\n",
      "Epoch 9120: Train Loss = 0.2536, Val Loss = 0.2619\n",
      "Epoch 9130: Train Loss = 0.2536, Val Loss = 0.2618\n",
      "Epoch 9140: Train Loss = 0.2535, Val Loss = 0.2618\n",
      "Epoch 9150: Train Loss = 0.2535, Val Loss = 0.2617\n",
      "Epoch 9160: Train Loss = 0.2534, Val Loss = 0.2617\n",
      "Epoch 9170: Train Loss = 0.2534, Val Loss = 0.2617\n",
      "Epoch 9180: Train Loss = 0.2533, Val Loss = 0.2616\n",
      "Epoch 9190: Train Loss = 0.2533, Val Loss = 0.2617\n",
      "Epoch 9200: Train Loss = 0.2554, Val Loss = 0.2663\n",
      "Epoch 9210: Train Loss = 0.8128, Val Loss = 1.2786\n",
      "Epoch 9220: Train Loss = 1.7156, Val Loss = 0.4370\n",
      "Epoch 9230: Train Loss = 1.5034, Val Loss = 0.2661\n",
      "Epoch 9240: Train Loss = 0.3921, Val Loss = 0.3428\n",
      "Epoch 9250: Train Loss = 0.2537, Val Loss = 0.4006\n",
      "Epoch 9260: Train Loss = 0.2725, Val Loss = 0.3476\n",
      "Epoch 9270: Train Loss = 0.2692, Val Loss = 0.2973\n",
      "Epoch 9280: Train Loss = 0.2603, Val Loss = 0.2738\n",
      "Epoch 9290: Train Loss = 0.2552, Val Loss = 0.2649\n",
      "Epoch 9300: Train Loss = 0.2533, Val Loss = 0.2619\n",
      "Epoch 9310: Train Loss = 0.2528, Val Loss = 0.2611\n",
      "Epoch 9320: Train Loss = 0.2529, Val Loss = 0.2611\n",
      "Epoch 9330: Train Loss = 0.2529, Val Loss = 0.2612\n",
      "Epoch 9340: Train Loss = 0.2528, Val Loss = 0.2612\n",
      "Epoch 9350: Train Loss = 0.2527, Val Loss = 0.2610\n",
      "Epoch 9360: Train Loss = 0.2527, Val Loss = 0.2609\n",
      "Epoch 9370: Train Loss = 0.2526, Val Loss = 0.2609\n",
      "Epoch 9380: Train Loss = 0.2526, Val Loss = 0.2609\n",
      "Epoch 9390: Train Loss = 0.2525, Val Loss = 0.2608\n",
      "Epoch 9400: Train Loss = 0.2525, Val Loss = 0.2608\n",
      "Epoch 9410: Train Loss = 0.2525, Val Loss = 0.2608\n",
      "Epoch 9420: Train Loss = 0.2524, Val Loss = 0.2607\n",
      "Epoch 9430: Train Loss = 0.2524, Val Loss = 0.2607\n",
      "Epoch 9440: Train Loss = 0.2524, Val Loss = 0.2607\n",
      "Epoch 9450: Train Loss = 0.2523, Val Loss = 0.2606\n",
      "Epoch 9460: Train Loss = 0.2523, Val Loss = 0.2606\n",
      "Epoch 9470: Train Loss = 0.2522, Val Loss = 0.2605\n",
      "Epoch 9480: Train Loss = 0.2522, Val Loss = 0.2605\n",
      "Epoch 9490: Train Loss = 0.2522, Val Loss = 0.2605\n",
      "Epoch 9500: Train Loss = 0.2521, Val Loss = 0.2604\n",
      "Epoch 9510: Train Loss = 0.2521, Val Loss = 0.2604\n",
      "Epoch 9520: Train Loss = 0.2521, Val Loss = 0.2604\n",
      "Epoch 9530: Train Loss = 0.2529, Val Loss = 0.2624\n",
      "Epoch 9540: Train Loss = 0.4323, Val Loss = 0.5901\n",
      "Epoch 9550: Train Loss = 12.5351, Val Loss = 7.4490\n",
      "Epoch 9560: Train Loss = 3.2496, Val Loss = 3.6269\n",
      "Epoch 9570: Train Loss = 1.4425, Val Loss = 1.3083\n",
      "Epoch 9580: Train Loss = 0.7106, Val Loss = 0.5187\n",
      "Epoch 9590: Train Loss = 0.4006, Val Loss = 0.3141\n",
      "Epoch 9600: Train Loss = 0.2983, Val Loss = 0.2728\n",
      "Epoch 9610: Train Loss = 0.2679, Val Loss = 0.2649\n",
      "Epoch 9620: Train Loss = 0.2582, Val Loss = 0.2631\n",
      "Epoch 9630: Train Loss = 0.2544, Val Loss = 0.2622\n",
      "Epoch 9640: Train Loss = 0.2525, Val Loss = 0.2614\n",
      "Epoch 9650: Train Loss = 0.2517, Val Loss = 0.2605\n",
      "Epoch 9660: Train Loss = 0.2516, Val Loss = 0.2600\n",
      "Epoch 9670: Train Loss = 0.2516, Val Loss = 0.2598\n",
      "Epoch 9680: Train Loss = 0.2516, Val Loss = 0.2598\n",
      "Epoch 9690: Train Loss = 0.2515, Val Loss = 0.2598\n",
      "Epoch 9700: Train Loss = 0.2515, Val Loss = 0.2598\n",
      "Epoch 9710: Train Loss = 0.2514, Val Loss = 0.2598\n",
      "Epoch 9720: Train Loss = 0.2514, Val Loss = 0.2597\n",
      "Epoch 9730: Train Loss = 0.2514, Val Loss = 0.2597\n",
      "Epoch 9740: Train Loss = 0.2514, Val Loss = 0.2597\n",
      "Epoch 9750: Train Loss = 0.2513, Val Loss = 0.2597\n",
      "Epoch 9760: Train Loss = 0.2513, Val Loss = 0.2596\n",
      "Epoch 9770: Train Loss = 0.2513, Val Loss = 0.2596\n",
      "Epoch 9780: Train Loss = 0.2512, Val Loss = 0.2596\n",
      "Epoch 9790: Train Loss = 0.2512, Val Loss = 0.2595\n",
      "Epoch 9800: Train Loss = 0.2512, Val Loss = 0.2595\n",
      "Epoch 9810: Train Loss = 0.2511, Val Loss = 0.2595\n",
      "Epoch 9820: Train Loss = 0.2511, Val Loss = 0.2594\n",
      "Epoch 9830: Train Loss = 0.2511, Val Loss = 0.2594\n",
      "Epoch 9840: Train Loss = 0.2510, Val Loss = 0.2594\n",
      "Epoch 9850: Train Loss = 0.2511, Val Loss = 0.2593\n",
      "Epoch 9860: Train Loss = 0.2570, Val Loss = 0.2677\n",
      "Epoch 9870: Train Loss = 1.8632, Val Loss = 3.0330\n",
      "Epoch 9880: Train Loss = 2.6024, Val Loss = 5.9809\n",
      "Epoch 9890: Train Loss = 0.6862, Val Loss = 2.0377\n",
      "Epoch 9900: Train Loss = 0.6292, Val Loss = 1.0380\n",
      "Epoch 9910: Train Loss = 0.4846, Val Loss = 0.5438\n",
      "Epoch 9920: Train Loss = 0.3537, Val Loss = 0.3504\n",
      "Epoch 9930: Train Loss = 0.2895, Val Loss = 0.2896\n",
      "Epoch 9940: Train Loss = 0.2646, Val Loss = 0.2711\n",
      "Epoch 9950: Train Loss = 0.2553, Val Loss = 0.2645\n",
      "Epoch 9960: Train Loss = 0.2519, Val Loss = 0.2615\n",
      "Epoch 9970: Train Loss = 0.2508, Val Loss = 0.2599\n",
      "Epoch 9980: Train Loss = 0.2507, Val Loss = 0.2591\n",
      "Epoch 9990: Train Loss = 0.2507, Val Loss = 0.2589\n",
      "Test Loss: 0.2725\n",
      "\n",
      "MAE: 0.3670\n",
      "RMSE: 0.5227\n",
      "R² Score: 0.9975\n",
      "\n",
      "Prediction Accuracy:\n",
      "- Exact matches: 10.2%\n",
      "- within 0.1: 17.8%\n",
      "- within 0.5: 79.3%\n",
      "- Within ±1°C: 95.0%\n",
      "- Within ±2°C: 99.5%\n"
     ]
    }
   ],
   "source": [
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(LinearRegressionModel, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "linear_model = LinearRegressionModel(input_dim=X_train.shape[1])\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(linear_model.parameters(), lr=0.01)\n",
    "\n",
    "EPOCHS = 10000\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    linear_model.train()\n",
    "    y_pred = linear_model(X_train)\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        linear_model.eval()\n",
    "        val_pred = linear_model(X_val)\n",
    "        val_loss = loss_fn(val_pred, y_val)\n",
    "        print(f\"Epoch {epoch}: Train Loss = {loss.item():.4f}, Val Loss = {val_loss.item():.4f}\")\n",
    "\n",
    "linear_model.eval()\n",
    "test_pred = linear_model(X_test)\n",
    "test_loss = loss_fn(test_pred, y_test)\n",
    "print(f\"Test Loss: {test_loss.item():.4f}\")\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Convert predictions and targets to numpy arrays\n",
    "y_true = y_test.detach().numpy()\n",
    "y_pred_np = test_pred.detach().numpy().round(1)\n",
    "\n",
    "mae = mean_absolute_error(y_true, y_pred_np)\n",
    "rmse = np.sqrt(mean_squared_error(y_true, y_pred_np))\n",
    "r2 = r2_score(y_true, y_pred_np)\n",
    "exact_matches = np.mean(np.abs(y_true - y_pred_np) == 0) * 100\n",
    "within_01 = np.mean(np.abs(y_true - y_pred_np) <= 0.1) * 100\n",
    "within_05 = np.mean(np.abs(y_true - y_pred_np) <= 0.5) * 100\n",
    "within_1 = np.mean(np.abs(y_true - y_pred_np) <= 1) * 100\n",
    "within_2 = np.mean(np.abs(y_true - y_pred_np) <= 2) * 100\n",
    "\n",
    "print()\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"R² Score: {r2:.4f}\")\n",
    "print(\"\\nPrediction Accuracy:\")\n",
    "print(f\"- Exact matches: {exact_matches:.1f}%\")\n",
    "print(f\"- within 0.1: {within_01:.1f}%\")\n",
    "print(f\"- within 0.5: {within_05:.1f}%\")\n",
    "print(f\"- Within ±1°C: {within_1:.1f}%\")\n",
    "print(f\"- Within ±2°C: {within_2:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-Layer Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TemperaturePredictor(\n",
      "  (fc1): Linear(in_features=39, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class TemperaturePredictor(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 1)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        return self.fc3(x)\n",
    "\n",
    "model = TemperaturePredictor(input_size=len(features))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50 | Train Loss: 5.7790 | Val Loss: 1.5994\n",
      "Epoch 10/50 | Train Loss: 3.2931 | Val Loss: 2.1640\n",
      "Epoch 15/50 | Train Loss: 3.0056 | Val Loss: 2.4554\n",
      "Epoch 20/50 | Train Loss: 3.0116 | Val Loss: 2.6317\n",
      "Epoch 25/50 | Train Loss: 3.0013 | Val Loss: 2.6678\n",
      "Epoch 30/50 | Train Loss: 2.9836 | Val Loss: 2.6628\n",
      "Epoch 35/50 | Train Loss: 2.9942 | Val Loss: 2.6632\n",
      "Epoch 40/50 | Train Loss: 2.9732 | Val Loss: 2.6635\n",
      "Epoch 45/50 | Train Loss: 2.9743 | Val Loss: 2.6637\n",
      "Epoch 50/50 | Train Loss: 2.9977 | Val Loss: 2.6687\n"
     ]
    }
   ],
   "source": [
    "def train_model(model, train_loader, val_loader, epochs=50):\n",
    "    train_losses, val_losses = [], []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in val_loader:\n",
    "                outputs = model(X_batch)\n",
    "                val_loss += criterion(outputs, y_batch).item()\n",
    "        \n",
    "        # Store losses\n",
    "        train_losses.append(train_loss / len(train_loader))\n",
    "        val_losses.append(val_loss / len(val_loader))\n",
    "        scheduler.step(val_losses[-1])\n",
    "        \n",
    "        # Print progress\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {train_losses[-1]:.4f} | Val Loss: {val_losses[-1]:.4f}\")\n",
    "    \n",
    "    return train_losses, val_losses\n",
    "\n",
    "train_losses, val_losses = train_model(model, train_loader, val_loader, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss (MSE): 3.0566\n",
      "MAE: 1.516028642654419°C\n",
      "RMSE: 1.749852651114774°C\n",
      "R²: 0.9720190167427063\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_loss = 0\n",
    "predictions, actuals = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        outputs = model(X_batch)\n",
    "        test_loss += criterion(outputs, y_batch).item()\n",
    "        predictions.extend(outputs.numpy().flatten())\n",
    "        actuals.extend(y_batch.numpy().flatten())\n",
    "\n",
    "test_loss /= len(test_loader)\n",
    "print(f\"Test Loss (MSE): {test_loss:.4f}\")\n",
    "\n",
    "predictions = np.array(predictions)\n",
    "actuals = np.array(actuals)\n",
    "\n",
    "print(f\"MAE: {mean_absolute_error(actuals, predictions)}°C\")\n",
    "print(f\"RMSE: {np.sqrt(mean_squared_error(actuals, predictions))}°C\")\n",
    "print(f\"R²: {r2_score(actuals, predictions)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
